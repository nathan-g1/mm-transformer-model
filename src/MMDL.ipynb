{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install seaborn\n",
    "LIMIT_BATCH_SIZE = 3900\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n",
    "from matplotlib.figure import Figure\n",
    "from rasterio.windows import Window\n",
    "from rasterio.transform import xy\n",
    "import os\n",
    "import geopandas as gpd\n",
    "import glob\n",
    "import random\n",
    "import pandas as pd\n",
    "from rembg import remove\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "## Fusion imports\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.layers import Dense, Concatenate, Input, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.models import Model\n",
    "from keras.utils import normalize\n",
    "\n",
    "import tensorflow.keras.backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dropout\n",
    "#from keras.layers import CuDNNLSTM\n",
    "from keras.layers import Dense, Concatenate\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/nathan/Documents/Files/Grad/UTSA/Courses/Thesis/mm-transformer-model/S2_tif\n"
     ]
    }
   ],
   "source": [
    "path1 = os.path.abspath('../')\n",
    "path_ATL03 = os.path.join(path1, \"IS2_LSTM\")\n",
    "path_s2 = os.path.join(path1, \"S2_tif\")\n",
    "path_csv = os.path.join(path1, \"csv\")\n",
    "path_before_training = os.path.join(path1, \"Before_training\")\n",
    "print(path_s2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def tensor_identity(shape):\n",
    "    # Initialize an empty tensor of zeros\n",
    "    samples, timesteps, features = shape\n",
    "    identity_tensor = np.zeros((samples, timesteps, features))\n",
    "\n",
    "    # Fill in the pseudo-identity matrices for each slice\n",
    "    for i in range(samples):\n",
    "        # Place ones along the diagonal, limiting to the minimum dimension\n",
    "        np.fill_diagonal(identity_tensor[i], 1)\n",
    "\n",
    "    return identity_tensor\n",
    "def create_zero_padded_image_tensor(shape):\n",
    "    samples, height, width, channels = shape\n",
    "    zero_padded_tensor = np.zeros((samples, height, width, channels))\n",
    "    return zero_padded_tensor\n",
    "\n",
    "def get_lstm_model():\n",
    "    units = 32\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units, activation='elu', input_shape=(5, 4)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(16, activation='elu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(16, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "\n",
    "    sample_weight=np.array([0.10, 0.35, 0.65])\n",
    "\n",
    "    # Define the optimizer with a specific learning rate\n",
    "    learning_rate = 0.005\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "    focal_loss = tf.keras.losses.CategoricalFocalCrossentropy(\n",
    "        alpha=sample_weight,\n",
    "        gamma=2.0,\n",
    "        from_logits=False,\n",
    "        label_smoothing=0.0,\n",
    "        axis=-1,\n",
    "        reduction='sum_over_batch_size',\n",
    "        name='categorical_focal_crossentropy'\n",
    "    )\n",
    "    model.compile(optimizer=optimizer, loss=focal_loss, metrics=['accuracy', f1_m,precision_m, recall_m])\n",
    "    return model\n",
    "\n",
    "\n",
    "# early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "# lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5)\n",
    "\n",
    "def train_model(\n",
    "    model,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_val,\n",
    "    y_val,\n",
    "    epochs=50,\n",
    "    batch_size=BATCH_SIZE):\n",
    "    \"\"\"\n",
    "    Train the model with validation\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    begin = time.time()\n",
    "    history = model.fit(\n",
    "        X_train,  # Input data for the single modality\n",
    "        y_train,  # Target labels\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        verbose=1,\n",
    "        callbacks=[early_stopping, lr_scheduler]\n",
    "    )\n",
    "    end = time.time()\n",
    "    print(f\"The training time is {end - begin} seconds.\")\n",
    "    return history\n",
    "# Evaluates a single modality model\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Evaluate model and print classification metrics\n",
    "    \"\"\"\n",
    "    # Get predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "    y_test_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "    num_classes = len(np.unique(y_test_classes))\n",
    "    class_names = ['Class ' + str(i) for i in range(num_classes)]\n",
    "    \n",
    "    # Print classification report\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test_classes, y_pred_classes, target_names=class_names))\n",
    "    \n",
    "    # Create confusion matrix\n",
    "    cm = confusion_matrix(y_test_classes, y_pred_classes)\n",
    "    # Normalize the confusion matrix\n",
    "    cm_percentage = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] * 100\n",
    "\n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm_percentage, annot=True, fmt='.2f', xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    \n",
    "    # Calculate and return metrics\n",
    "    test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=1)\n",
    "    return test_loss, test_accuracy\n",
    "\n",
    "# Evaluates a fusion model\n",
    "def evaluate_fusion_model(model, X_test_unet, X_test_lstm, y_test):\n",
    "    \"\"\"\n",
    "    Evaluate model and print classification metrics\n",
    "    \"\"\"\n",
    "    # Get predictions\n",
    "    y_pred = model.predict([X_test_unet, X_test_lstm])\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "    y_test_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "    # class_names = ['Thick Ice ', 'Thin Ice', 'Open Water']\n",
    "    num_classes = len(np.unique(y_test_classes))\n",
    "    class_names = ['Class ' + str(i) for i in range(num_classes)]\n",
    "    # Print classification report\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test_classes, y_pred_classes, target_names=class_names))\n",
    "    \n",
    "    # Create confusion matrix\n",
    "    cm = confusion_matrix(y_test_classes, y_pred_classes)\n",
    "    # Normalize the confusion matrix\n",
    "    cm_percentage = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] * 100\n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm_percentage, annot=True, fmt='.2f', xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.show(block=False)\n",
    "    \n",
    "    # Calculate and return metrics\n",
    "    results = model.evaluate([X_test_unet, X_test_lstm], y_test, verbose=1)\n",
    "    test_loss = results[0]\n",
    "    test_accuracy = results[1]\n",
    "    print(f\"\\nTest Loss: {test_loss:.4f}\")\n",
    "    print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "    return test_loss, test_accuracy\n",
    "\n",
    "\n",
    "def train_fusion_model(\n",
    "    model,\n",
    "    X_train_unet,\n",
    "    X_train_lstm,\n",
    "    y_train,\n",
    "    X_val_unet,\n",
    "    X_val_lstm,\n",
    "    y_val,\n",
    "    epochs=50,\n",
    "    batch_size=BATCH_SIZE\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Train the fusion model with validation\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # 3. Use a custom learning rate and optimizer\n",
    "    lr_scheduler = ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=5,\n",
    "        min_lr=1e-6,\n",
    "        mode='min',\n",
    "        verbose=1\n",
    "    )\n",
    "    # 4. Implement improved callbacks\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=10,\n",
    "        restore_best_weights=True,\n",
    "        mode='min'\n",
    "    )\n",
    "\n",
    "    checkpoint = ModelCheckpoint(\n",
    "        'best_mlf_model.keras',\n",
    "        monitor='val_loss',\n",
    "        save_best_only=True,\n",
    "        mode='min',\n",
    "        verbose=1\n",
    "    )\n",
    "    begin = time.time()\n",
    "    history = model.fit(\n",
    "        [X_train_unet, X_train_lstm],  # Input data for both branches\n",
    "        y_train,                        # Target labels\n",
    "        validation_data=([X_val_unet, X_val_lstm], y_val),\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        verbose=1,\n",
    "        callbacks=[early_stopping, lr_scheduler, checkpoint],\n",
    "        class_weight=None  # Add class weights if dataset is imbalanced\n",
    "    )\n",
    "    end = time.time()\n",
    "    print(f\"The training time is {end - begin} seconds.\")\n",
    "    return history\n",
    "\n",
    "# Function to plot training history\n",
    "def plot_training_history(history):\n",
    "    \"\"\"\n",
    "    Plot training and validation metrics\n",
    "    \"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # Plot accuracy\n",
    "    ax1.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "    ax1.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    ax1.set_title('Model Accuracy')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Accuracy')\n",
    "    ax1.legend()\n",
    "    \n",
    "    # Plot loss\n",
    "    ax2.plot(history.history['loss'], label='Training Loss')\n",
    "    ax2.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    ax2.set_title('Model Loss')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Loss')\n",
    "    ax2.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    # save the figure to a file. Grab model name from history\n",
    "    name = history.model.name\n",
    "    fig.savefig(name + '_training_history.png')\n",
    "    return fig\n",
    "\n",
    "def color_segmentation(img):\n",
    "    # Get a \"mask\" over the image for each pixel\n",
    "    # if a pixel's color is between the lower and upper white, its mask is 1\n",
    "    # Otherwise, the pixel's mask is 0\n",
    "    hsv_img = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "    \n",
    "    lower_ice = (0, 0, 205)#(127, 7, 94) #increase v to specify ow\n",
    "    upper_ice = (185, 255, 255)#(147, 53, 232) #increase h to specify si\n",
    "    mask_ice = cv2.inRange(hsv_img, lower_ice, upper_ice)\n",
    "    \n",
    "    lower_tice = (0, 0, 31)#(127, 7, 94) #increase v to specify ow\n",
    "    upper_tice = (185, 255, 204)#(147, 53, 232) #increase h to specify si\n",
    "    mask_tice = cv2.inRange(hsv_img, lower_tice, upper_tice)\n",
    "    \n",
    "    lower_water = (0, 0, 0)#(127, 7, 94) #increase v to specify ow\n",
    "    upper_water = (185, 255, 30)#(147, 53, 232) #increase h to specify si\n",
    "    mask_water = cv2.inRange(hsv_img, lower_water, upper_water)\n",
    "    \n",
    "    # duplicate the image\n",
    "    seg_img = img.copy()\n",
    "    #color each masked portion\n",
    "    seg_img[mask_ice == 255] = [255, 0, 0]\n",
    "    seg_img[mask_tice == 255] = [0, 0, 255]\n",
    "    seg_img[mask_water == 255] = [0, 255, 0]\n",
    "    \n",
    "    #seg_img = cv2.cvtColor(seg_img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    return seg_img\n",
    "\n",
    "def shadow_cloud_removal(ori):\n",
    "\n",
    "    ### seperate open water\n",
    "    lower_water = (0, 0, 0)\n",
    "    upper_water = (185, 255, 30)\n",
    "    hsv_img = cv2.cvtColor(ori, cv2.COLOR_RGB2HSV)\n",
    "    mask_water = (cv2.inRange(hsv_img, lower_water, upper_water))\n",
    "\n",
    "    # duplicate the image\n",
    "    without_water_img = ori.copy()\n",
    "    without_water_img[mask_water == 255] = [255, 255, 255]\n",
    "    #plot_image(ori, water_img)\n",
    "\n",
    "    #img = cv2.imread('s2_vis_2.png',cv2.IMREAD_GRAYSCALE)\n",
    "    img = cv2.cvtColor(without_water_img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    dilated_img = cv2.dilate(img, np.ones((7,7), np.uint8))\n",
    "    bg_img = cv2.medianBlur(dilated_img, 155)\n",
    "    diff_img = 255 - cv2.absdiff(img, bg_img)\n",
    "\n",
    "    ret2, outs2 = cv2.threshold(src = diff_img, thresh = 0, maxval = 255, type = cv2.THRESH_OTSU+cv2.THRESH_BINARY)\n",
    "    diff_img2 = cv2.bitwise_and(diff_img, outs2)\n",
    "\n",
    "    norm_img = cv2.normalize(diff_img2, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8UC1)\n",
    "    _, thr_img = cv2.threshold(norm_img, 235, 0, cv2.THRESH_TRUNC)\n",
    "    thr_img = cv2.normalize(thr_img, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8UC1)\n",
    "\n",
    "    ### seperate thin and old ice\n",
    "    old_thin_ice = cv2.cvtColor(thr_img,cv2.COLOR_GRAY2RGB)\n",
    "    hsv_img = cv2.cvtColor(old_thin_ice, cv2.COLOR_RGB2HSV)\n",
    "\n",
    "    lower_tice = (0, 0, 0)\n",
    "    upper_tice = (185, 255, 204)\n",
    "    mask_tice = cv2.inRange(hsv_img, lower_tice, upper_tice)\n",
    "\n",
    "    lower_ice = (0, 0, 205)\n",
    "    upper_ice = (185, 255, 255)\n",
    "    mask_ice = cv2.inRange(hsv_img, lower_ice, upper_ice)\n",
    "    mask_ice = cv2.bitwise_xor(mask_water, mask_ice)\n",
    "    #plot_image3(mask_water, mask_tice, mask_ice)\n",
    "\n",
    "    # duplicate the image\n",
    "    shadow_free = old_thin_ice.copy()\n",
    "    #color each masked portion\n",
    "    shadow_free[mask_ice == 255] = [255, 255, 255]\n",
    "    shadow_free[mask_tice == 255] = [155, 155, 155]\n",
    "    shadow_free[mask_water == 255] = [0, 0, 0]\n",
    "    shadow_free = cv2.cvtColor(shadow_free, cv2.COLOR_BGR2RGB)\n",
    "    #plot_image(shadow_free, ori)\n",
    "\n",
    "    #segmentation\n",
    "    #img = cv2.cvtColor(water_img,cv2.COLOR_GRAY2RGB)\n",
    "    seg_img = color_segmentation(ori)\n",
    "    #plot_image(ori, seg_img, title_1 = \"Original Image\", title_2 = \"Segmented original image\")\n",
    "\n",
    "    #final = cv2.cvtColor(shadow_free,cv2.COLOR_GRAY2RGB)\n",
    "    seg_res = color_segmentation(shadow_free)\n",
    "    #gray = cv2.cvtColor(seg_res,cv2.COLOR_RGB2GRAY)\n",
    "    #plot_image(shadow_free, seg_res, title_1 = \"Shadow free Image\", title_2 = \"Segmented shadow free image\")\n",
    "    \n",
    "    #return seg_img, shadow_free, seg_res\n",
    "    return seg_res\n",
    "\n",
    "\n",
    "def rgba2rgb( rgba, background=(0,0,0)):\n",
    "    row, col, ch = rgba.shape\n",
    "    if ch == 3:\n",
    "        return rgba\n",
    "    assert ch == 4, 'RGBA image has 4 channels.'\n",
    "    rgb = np.zeros( (row, col, 3), dtype='float32' )\n",
    "    r, g, b, a = rgba[:,:,0], rgba[:,:,1], rgba[:,:,2], rgba[:,:,3]\n",
    "    a = np.asarray( a, dtype='float32' ) / 255.0\n",
    "    R, G, B = background\n",
    "    rgb[:,:,0] = r * a + (1.0 - a) * R\n",
    "    rgb[:,:,1] = g * a + (1.0 - a) * G\n",
    "    rgb[:,:,2] = b * a + (1.0 - a) * B\n",
    "    return np.asarray( rgb, dtype='uint8' )\n",
    "\n",
    "def plot_image(image_1, image_2,title_1=\"Orignal\",title_2=\"New Image\"):\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(cv2.cvtColor(image_1, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(title_1)\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(cv2.cvtColor(image_2, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(title_2)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    y_true = K.cast(y_true, 'float32')\n",
    "    y_pred = K.cast(y_pred, 'float32')\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    y_true = K.cast(y_true, 'float32')\n",
    "    y_pred = K.cast(y_pred, 'float32')\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2 * ((precision * recall) / (precision+recall+K.epsilon()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file paths\n",
    "tiff_files = ['s2_vis_00_20191103T183459_20191103T183502_T05CMR.tif', 's2_vis_01_20191103T183459_20191103T183502_T05CMS.tif']\n",
    "\n",
    "\n",
    "# Get list of TIFF files\n",
    "tiff_files = sorted(glob.glob(os.path.join(path_s2, \"*.tif\")))\n",
    "\n",
    "# Get list of CSV files\n",
    "csv_files = sorted(glob.glob(os.path.join(path_csv, \"*.csv\")))\n",
    "\n",
    "# Select two random CSV files\n",
    "selected_csv_files = random.sample(csv_files, 2)\n",
    "\n",
    "# ATL03 to S2 mapping file\n",
    "atl03_to_s2_mapping_file = pd.read_csv(os.path.join(path1, \"ATL03_S2_2019-11-01_2019-11-30_ross.csv\"))\n",
    "\n",
    "# Corrected ATL03 to S2 mapping file\n",
    "cleaned_atl03_to_s2_mapping_file = pd.read_csv(os.path.join(path1, \"clean\", \"cleaned_data_indexed.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show 100x100 Grid Lines (Work on first two files only)\n",
    "def show_100x100_grid_lines_on_tif_files():\n",
    "    for file in tiff_files[:2]:\n",
    "        with rasterio.open(file) as img:\n",
    "            width, height = img.width, img.height\n",
    "            transform = img.transform\n",
    "\n",
    "            # Generate grid lines\n",
    "            x_coords = np.linspace(0, width, 101)\n",
    "            y_coords = np.linspace(0, height, 101)\n",
    "\n",
    "            # Plot grid lines\n",
    "            plt.figure(figsize=(10, 10))\n",
    "            plt.imshow(img.read(1), cmap='gray')\n",
    "            for x in x_coords:\n",
    "                plt.axvline(x, color='red', linewidth=0.5)\n",
    "            for y in y_coords:\n",
    "                plt.axhline(y, color='red', linewidth=0.5)\n",
    "            plt.title(f'Grid Lines for {os.path.basename(file)}')\n",
    "            plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_csv_if_exists(file):\n",
    "    print(file)\n",
    "    if os.path.exists(file) and os.path.isfile(file):\n",
    "        return pd.read_csv(file)\n",
    "    return None\n",
    "\n",
    "# Function to get coordinates list\n",
    "def get_coordinates_list(file):\n",
    "    # Extract the date in YYYYMMDD format from the filename\n",
    "    date = os.path.basename(file).split(\"_\")[3].split(\"T\")[0]\n",
    "    dataset = cleaned_atl03_to_s2_mapping_file\n",
    "    dataset['transformed_date'] = dataset['date'] // 1000000\n",
    "    # Filter by date and get all unique rows with their original indices\n",
    "    # df = dataset[dataset['date'] == int(date)].drop_duplicates(subset=['index', 'lat', 'lon'])\n",
    "    df = dataset[dataset['transformed_date'] == int(date)][['index', 'lat', 'lon']].drop_duplicates(subset=['lat', 'lon'])\n",
    "\n",
    "    # Create a list of coordinates with their original indices\n",
    "    coordinates_with_indices = list(zip(df['index'], df['lat'], df['lon']))\n",
    "\n",
    "    return coordinates_with_indices  # List of (lat, lon, index) tuples\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Images, Grids, coordinates, patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_patches_from_coordinates(file):\n",
    "    img = rasterio.open(file, crs='EPSG:3976')\n",
    "    raw = img.read(1)\n",
    "    raw[raw < 0] = 0\n",
    "\n",
    "    ori = img.read()\n",
    "    ori[ori < 0] = 0\n",
    "    ori = ori.swapaxes(0, 1)\n",
    "    ori = ori.swapaxes(1, 2)\n",
    "\n",
    "    img_array = ori\n",
    "    img_array[img_array < 0] = 0\n",
    "    # mask creation\n",
    "    copy_img = img.read()\n",
    "    copy_img[copy_img < 0] = 0\n",
    "    copy_img = copy_img.swapaxes(0, 1)\n",
    "    copy_img = copy_img.swapaxes(1, 2)\n",
    "    mask = shadow_cloud_removal(copy_img)\n",
    "    mask[mask < 0] = 0\n",
    "\n",
    "    height = img_array.shape[0]\n",
    "    width = img_array.shape[1]\n",
    "    cols, rows = np.meshgrid(np.arange(width), np.arange(height))\n",
    "    xs, ys = rasterio.transform.xy(img.transform, rows, cols)\n",
    "    xs = np.array(xs)\n",
    "    ys = np.array(ys)\n",
    "\n",
    "    coordinates_list = get_coordinates_list(file)\n",
    "    df = pd.DataFrame(coordinates_list, columns=['index', 'lat', 'lon'])\n",
    "    gdf = gpd.GeoDataFrame(df, geometry=gpd.points_from_xy(df.lon, df.lat))\n",
    "    gdf.crs = \"+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs\"\n",
    "    gdf = gdf.to_crs('epsg:3976')\n",
    "\n",
    "    gdf['x'] = gdf.geometry.apply(lambda x: x.x)\n",
    "    gdf['y'] = gdf.geometry.apply(lambda x: x.y)\n",
    "\n",
    "    df = pd.DataFrame(gdf)\n",
    "    x_min = xs.min()\n",
    "    x_max = xs.max()\n",
    "    y_min = ys.min()\n",
    "    y_max = ys.max()\n",
    "    df = df[(df[\"x\"] >= x_min) & (df[\"x\"] <= x_max) & (df[\"y\"] >= y_min) & (df[\"y\"] <= y_max)]\n",
    "\n",
    "    # Map coordinates to pixel indices\n",
    "    pixel_coords = [img.index(x, y) for x, y in zip(df['x'], df['y'])]\n",
    "\n",
    "    # Dimensions for each patch\n",
    "    patch_size = 100\n",
    "    half_patch = patch_size // 2\n",
    "\n",
    "    # List to store the patches\n",
    "    patches = []\n",
    "    # List to store the mask patches\n",
    "    mask_patches = []\n",
    "\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(raw, cmap='gray')\n",
    "    print(f\"Number of patches for {file}: {len(pixel_coords)}\")\n",
    "    uil = len(pixel_coords)\n",
    "    for idx, (row_idx, col_idx) in enumerate(pixel_coords):  # Using enumerate to get the index\n",
    "        # Get the corresponding index from the DataFrame\n",
    "        index = df['index'].iloc[idx]\n",
    "\n",
    "        # Ensure the 100x100 patch falls within the original image boundaries\n",
    "        if (row_idx - half_patch >= 0 and row_idx + half_patch < height and \n",
    "            col_idx - half_patch >= 0 and col_idx + half_patch < width):\n",
    "\n",
    "            # Extract the 100x100 patch\n",
    "            patch = img_array[row_idx - half_patch:row_idx + half_patch, \n",
    "                              col_idx - half_patch:col_idx + half_patch]\n",
    "            patches.append(patch)\n",
    "\n",
    "            # Extract the mask patch\n",
    "            mask_patch = mask[row_idx - half_patch:row_idx + half_patch, \n",
    "                              col_idx - half_patch:col_idx + half_patch]\n",
    "            mask_patches.append(mask_patch)\n",
    "\n",
    "            # display the bigger image with the patches on drawn in a thin rectangle\n",
    "            if (idx < (uil * 0.25)):\n",
    "                plt.plot([col_idx - half_patch, col_idx + half_patch, col_idx + half_patch, col_idx - half_patch, col_idx - half_patch],\n",
    "                        [row_idx - half_patch, row_idx - half_patch, row_idx + half_patch, row_idx + half_patch, row_idx - half_patch],\n",
    "                        color='red')\n",
    "                # Save the patch\n",
    "                patch_filename = os.path.join(path1, f'test_grid/patch_{index}_{row_idx}_{col_idx}.png')\n",
    "                plt.imsave(patch_filename, patch)\n",
    "            # Save the mask patch\n",
    "            # mask_patch_filename = os.path.join(path1, f'grid_images/mask/mask_patch_{index}_{row_idx}_{col_idx}.png')\n",
    "            # plt.imsave(mask_patch_filename, mask_patch)\n",
    "    plt.show()\n",
    "\n",
    "    return patches\n",
    "\n",
    "# for file in tiff_files:\n",
    "#     if os.path.basename(file) in [\"s2_vis_46_20191123T183459_20191123T183459_T04CEA.tif\"]:\n",
    "#     # if os.path.basename(file) in [\"s2_vis_41_20191120T200529_20191120T200529_T02CME.tif\", \"s2_vis_46_20191123T183459_20191123T183459_T04CEA.tif\"]:\n",
    "#         print(f\"Skipping {file}\")\n",
    "#         create_patches_from_coordinates(file)\n",
    "    # print(f\"Number of patches for {file}: {len(res[0])}\")\n",
    "    # print(f\"Number of mask patches for {file}: {len(res[1])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.savefig('sdf.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib\n",
    "# matplotlib.use('Agg')  # Use non-interactive backend\n",
    "# matplotlib.use('TkAgg')\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "def plot_grid_and_coordinates(file):\n",
    "    # Open image\n",
    "    img = rasterio.open(file, crs='EPSG:3976')\n",
    "\n",
    "    # Read the original image without any processing\n",
    "    original_img = img.read()\n",
    "    # Swap axes to get correct orientation (bands last)\n",
    "    original_img = original_img.swapaxes(0, 2)\n",
    "    original_img = original_img.swapaxes(0, 1)\n",
    "\n",
    "    # Get dimensions from original image\n",
    "    height = original_img.shape[0]\n",
    "    width = original_img.shape[1]\n",
    "\n",
    "    # Create coordinate grid\n",
    "    cols, rows = np.meshgrid(np.arange(width), np.arange(height))\n",
    "    xs, ys = rasterio.transform.xy(img.transform, rows, cols)\n",
    "    xs = np.array(xs)\n",
    "    ys = np.array(ys)\n",
    "\n",
    "    # Convert coordinates to GeoDataFrame\n",
    "    coordinates_list = get_coordinates_list(file)\n",
    "    df = pd.DataFrame(coordinates_list, columns=['index', 'lat', 'lon'])\n",
    "    gdf = gpd.GeoDataFrame(df, geometry=gpd.points_from_xy(df.lon, df.lat))\n",
    "    gdf.crs = \"+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs\"\n",
    "\n",
    "    # Transform to match the image's CRS\n",
    "    gdf = gdf.to_crs('epsg:3976')\n",
    "\n",
    "    # Extract transformed coordinates\n",
    "    gdf['x'] = gdf.geometry.apply(lambda x: x.x)\n",
    "    gdf['y'] = gdf.geometry.apply(lambda x: x.y)\n",
    "\n",
    "    # Filter coordinates\n",
    "    df = pd.DataFrame(gdf)\n",
    "    x_min = xs.min()\n",
    "    x_max = xs.max()\n",
    "    y_min = ys.min()\n",
    "    y_max = ys.max()\n",
    "    df = df[(df[\"x\"] >= x_min) & (df[\"x\"] <= x_max) & \n",
    "            (df[\"y\"] >= y_min) & (df[\"y\"] <= y_max)]\n",
    "\n",
    "    # Map coordinates to pixel indices\n",
    "    pixel_coords = [img.index(x, y) for x, y in zip(df['x'], df['y'])]\n",
    "\n",
    "    # Generate grid lines\n",
    "    x_coords = np.linspace(0, width, 33)\n",
    "    y_coords = np.linspace(0, height, 33)\n",
    "\n",
    "    # Plot\n",
    "    plt.imshow(original_img)  # Plot original image without any processing\n",
    "    # plt.vlines(x_coords, 0, height, color='red', linewidth=0.5)\n",
    "    # plt.hlines(y_coords, 0, width, color='red', linewidth=0.5)\n",
    "    \n",
    "    rows, cols = zip(*pixel_coords)\n",
    "    plt.scatter(cols, rows, color='blue', s=2)\n",
    "\n",
    "    plt.title(f'Grid Lines and Coordinates for {os.path.basename(file)}')\n",
    "    plt.show()\n",
    "    # save plot with all the grid lines and coordinates using plt.imsave\n",
    "    # since plt.imsave(f'{os.path.basename(file)}_grid_lines_and_coordinates.png', img) won't show the grid lines and coordinates\n",
    "    # we need to save the plot using plt.savefig and then read it using plt.imread\n",
    "    # plt.savefig(f'{os.path.basename(file)}_grid_lines_and_coordinates.png')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "# Plot grid lines and coordinates for the first two files\n",
    "# for file in tiff_files:\n",
    "#     if os.path.basename(file) in [\"s2_vis_46_20191123T183459_20191123T183459_T04CEA.tif\"]:\n",
    "#         plot_grid_and_coordinates(file)\n",
    "    # if os.path.basename(file) in [\"s2_vis_41_20191120T200529_20191120T200529_T02CME.tif\", \"s2_vis_27_20191116T184459_20191116T184458_T02CMU.tif\"]:\n",
    "    #     plot_grid_and_coordinates(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch and generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read ATLO3 files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file paths\n",
    "output_file = os.path.join(path1, \"clean\", \"cleaned_data_indexed.csv\")\n",
    "\n",
    "# separate features and labels\n",
    "dataset_accu = pd.read_csv(output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class distribution plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LIMIT_BATCH_SIZE = 2900\n",
    "# sampler_ds = dataset_accu.copy()\n",
    "\n",
    "# # Get the indices of each class\n",
    "# class_0_indices = sampler_ds[sampler_ds['label'] == 0].index\n",
    "# class_1_indices = sampler_ds[sampler_ds['label'] == 1].index\n",
    "# class_2_indices = sampler_ds[sampler_ds['label'] == 2].index\n",
    "\n",
    "# # Get the number of samples for each class\n",
    "# num_samples_class_0 = int(LIMIT_BATCH_SIZE * 0.333333)\n",
    "# num_samples_class_1 = int(LIMIT_BATCH_SIZE * 0.3)\n",
    "# num_samples_class_2 = int(LIMIT_BATCH_SIZE * 0.3)\n",
    "\n",
    "# # Get the random samples for each class\n",
    "# random_class_0_indices = np.random.choice(class_0_indices, num_samples_class_0, replace=False)\n",
    "# random_class_1_indices = np.random.choice(class_1_indices, num_samples_class_1, replace=False)\n",
    "# random_class_2_indices = np.random.choice(class_2_indices, num_samples_class_2, replace=False)\n",
    "\n",
    "# # Concatenate the random samples\n",
    "# random_indices = np.concatenate([random_class_0_indices, random_class_1_indices, random_class_2_indices])\n",
    "\n",
    "# # Get the sampled dataset\n",
    "# sampler_ds = sampler_ds.loc[random_indices]\n",
    "# images_path = os.path.join(path1, \"grid_images/train/\", \"*.png\")\n",
    "# images_mask_path = os.path.join(path1, \"grid_images/mask\")\n",
    "\n",
    "# # Get list of image files and mask files for the sampled dataset that matches the indices\n",
    "# image_files = sorted(glob.glob(images_path))\n",
    "# mask_files = sorted(glob.glob(images_mask_path + \"/*.png\"))\n",
    "\n",
    "# available_indices = set()\n",
    "# train_images_ = []\n",
    "# train_masks_ = []\n",
    "# for filename in sorted(glob.glob(images_path)):\n",
    "#     temp = os.path.basename(filename).split(\"_\")\n",
    "#     index = int(temp[1])\n",
    "#     if index not in random_indices:\n",
    "#         continue\n",
    "#     img = cv2.imread(filename, 0)\n",
    "#     if img is None:\n",
    "#         print(f\"Warning: Could not load image {filename}. Skipping.\")\n",
    "#         continue\n",
    "#     temp = temp[1:]\n",
    "#     temp = \"mask_patch_\" + \"_\".join(temp)\n",
    "#     temp = os.path.join(images_mask_path, temp)\n",
    "    \n",
    "#     if not os.path.exists(temp):\n",
    "#         continue\n",
    "#     ####################### ####################### ####################### ####################### #######################\n",
    "#     if index in available_indices: # VERY CRUCIAL   ####################### ####################### #######################\n",
    "#         continue\n",
    "#     available_indices.add(index)\n",
    "#     train_images_.append(filename)\n",
    "#     train_masks_.append(temp)\n",
    "\n",
    "# # print size of the train_images and train_masks\n",
    "# print(len(train_images_))\n",
    "# print(len(train_masks_))\n",
    "\n",
    "# # from available indices, get the corresponding labels\n",
    "# labels = []\n",
    "# for index in available_indices:\n",
    "#     labels.append(sampler_ds[sampler_ds['index'] == index]['label'].values[0])\n",
    "\n",
    "# # show plot of the labels distribution\n",
    "# plt.hist(labels, bins=3)\n",
    "# # count of each class\n",
    "# print(np.unique(labels, return_counts=True))\n",
    "\n",
    "# print(f\"Number of available indices: {len(available_indices)}\")\n",
    "# print(f\"Number of train images: {len(train_images_)}\")\n",
    "# print(f\"Number of train masks: {len(train_masks_)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image filtering based on ATLO3 files indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of available indices: 3267\n",
      "Number of train images: 3267\n",
      "Number of train masks: 3267\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# available indices set\n",
    "available_indices = set()\n",
    "train_images_ = []\n",
    "train_masks_ = []\n",
    "images_path = os.path.join(path1, \"grid_images/train/\", \"*.png\")\n",
    "images_mask_path = os.path.join(path1, \"grid_images/mask\")\n",
    "for filename in sorted(glob.glob(images_path))[:LIMIT_BATCH_SIZE]:\n",
    "    img = cv2.imread(filename, 0)\n",
    "    if img is None:\n",
    "        print(f\"Warning: Could not load image {filename}. Skipping.\")\n",
    "        continue\n",
    "    temp = os.path.basename(filename).split(\"_\")\n",
    "    index = int(temp[1])\n",
    "    temp = temp[1:]\n",
    "    temp = \"mask_patch_\" + \"_\".join(temp)\n",
    "    temp = os.path.join(images_mask_path, temp)\n",
    "    \n",
    "    if not os.path.exists(temp):\n",
    "        continue\n",
    "    ####################### ####################### ####################### ####################### #######################\n",
    "    if index in available_indices: # VERY CRUCIAL   ####################### ####################### #######################\n",
    "        continue\n",
    "    available_indices.add(index)\n",
    "    train_images_.append(filename)\n",
    "    train_masks_.append(temp)\n",
    "    ####################### ####################### ####################### ####################### #######################\n",
    "\n",
    "\n",
    "print(f\"Number of available indices: {len(available_indices)}\")\n",
    "print(f\"Number of train images: {len(train_images_)}\")\n",
    "print(f\"Number of train masks: {len(train_masks_)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Uni-modals here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model, clone_model\n",
    "from tensorflow.keras.layers import Flatten, Multiply, Dense, Input, Reshape, Lambda\n",
    "\n",
    "\n",
    "# Load the pre-trained UNet model\n",
    "unet_model = tf.keras.models.load_model('s2_multi_with_cloud_auto_labeled_50.keras')\n",
    "lstm_model = get_lstm_model()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lstm_features.shape (3267,)\n",
      "(3267, 21)\n",
      "(3267, 5, 4)\n",
      "The train set size is 1959, validation set size is 654, and testing set size is 654\n",
      "The shapes of training data are (1959, 5, 4) (1959, 3)\n",
      "The shapes of testing data are (654, 5, 4) (654, 3)\n",
      "The shapes of testing data are (654, 5, 4) (654, 3)\n"
     ]
    }
   ],
   "source": [
    "lstm_features = dataset_accu.copy()\n",
    "# remove rows with index not in available_indices\n",
    "lstm_features = lstm_features[lstm_features['index'].isin(available_indices)]\n",
    "lstm_labels = lstm_features.pop('label')\n",
    "lstm_track = lstm_features.pop('date')\n",
    "lstm_track = lstm_features.pop('lat')\n",
    "lstm_track = lstm_features.pop('lon')\n",
    "print(\"lstm_features.shape\", lstm_labels.shape)\n",
    "\n",
    "\n",
    "# normalized the features\n",
    "def norm(x, M = 1, m = 0):\n",
    "    # Normalize the input data\n",
    "    # output = (x-m)/(M-m) # Max-min normalization\n",
    "    output = (x-x.mean())/(M-x.std()) # mean-std normalization\n",
    "    return output\n",
    "\n",
    "norm_lstm_features = norm(lstm_features)\n",
    "norm_lstm_features\n",
    "\n",
    "\n",
    "# convert the data to LSTM format\n",
    "np_array = norm_lstm_features.to_numpy()\n",
    "print(np_array.shape)\n",
    "new_lstm_features = []\n",
    "for row in np_array:\n",
    "  # construct features array\n",
    "  point_r2 =  row[1:5]\n",
    "  point_r1 =  row[5:9]\n",
    "  point_0 = row[9:13]\n",
    "  point_l1 = row[13:17]\n",
    "  point_l2 = row[17:21]\n",
    "  new_lstm_features.append([point_r2, point_r1, point_0, point_l1, point_l2])\n",
    "\n",
    "new_lstm_features = np.array(new_lstm_features)\n",
    "print(new_lstm_features.shape) # the X array inputshape = [5,4]\n",
    "\n",
    "\n",
    "\n",
    "# covert labels to multi-class\n",
    "def convert_to_multi_calss(data):\n",
    "  new_labels = []\n",
    "  for label in data:\n",
    "    #print(row)\n",
    "    if label == 0:\n",
    "      new_labels.append([1,0,0]) \n",
    "    elif label == 1:\n",
    "      new_labels.append([0,1,0])\n",
    "    elif label == 2:\n",
    "      new_labels.append([0,0,1])\n",
    "    else:\n",
    "      print(\"Error: invalid label:\" + label)\n",
    "      return \n",
    "  return np.array(new_labels)\n",
    "\n",
    "lstm_labels_multi = convert_to_multi_calss(lstm_labels)\n",
    "lstm_labels_multi\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(new_lstm_features, lstm_labels_multi, \n",
    "                                                    test_size =0.2, shuffle=True, random_state=20)\n",
    "\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size =0.25, shuffle=True, random_state=20)\n",
    "\n",
    "print(\"The train set size is {0:d}, validation set size is {1:d}, \"\n",
    "      \"and testing set size is {2:d}\".format(len(X_train), len(X_val), len(X_test)))\n",
    "print(\"The shapes of training data are\", X_train.shape, Y_train.shape)\n",
    "print(\"The shapes of testing data are\", X_test.shape, Y_test.shape)\n",
    "print(\"The shapes of testing data are\", X_val.shape, Y_val.shape)\n",
    "\n",
    "\n",
    "#loss_func = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "loss_func = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSTM MODEL TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "############################################################################################################\n",
    "###########                      LSTM MODEL TRAINING                                         ###############\n",
    "############################################################################################################\n",
    "\"\"\"\n",
    "\n",
    "model = get_lstm_model()\n",
    "# plot_model(\n",
    "#     model, \n",
    "#     to_file='lst_model.png', \n",
    "#     show_shapes=True, \n",
    "#     show_layer_names=False, \n",
    "#     rankdir='TB', \n",
    "#     expand_nested=False, \n",
    "#     dpi=96\n",
    "# )\n",
    "# history = train_model(model, X_train, Y_train, X_val, Y_val, epochs=EPOCHS, batch_size=BATCH_SIZE)\n",
    "# plot_training_history(history)\n",
    "# test_loss, test_accuracy = evaluate_model(model, X_test, Y_test)\n",
    "\n",
    "# print(f\"\\nTest Loss: {test_loss:.4f}\")\n",
    "# print(f\"Test Accuracy: {test_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing images for UNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x] Save the UNet model in keras format\n",
    "- [x] Load the LSTM model in a variable\n",
    "- [x] Perform additive fusion\n",
    "- [x] Perform multiplication fusion\n",
    "- [x] Perform Gated fusion\n",
    "- [ ] Perform Nonlinear fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "214106112 214106112\n",
      "(3267, 256, 256) (3267, 256, 256)\n",
      "train image shape (3267, 256, 256)\n",
      "train masks shape (3267, 256, 256)\n",
      "\n",
      "train image shape (3267, 256, 256, 1)\n",
      "train masks input shape (3267, 256, 256, 1)\n",
      "Class values in the dataset are ...  [0 1 2]\n",
      "X_train_unet train image shape (2613, 256, 256, 1)\n",
      "X_test_unet train image shape (654, 256, 256, 1)\n",
      "y_train_cat shape (2613, 256, 256, 3)\n",
      "y_test_cat shape (654, 256, 256, 3)\n"
     ]
    }
   ],
   "source": [
    "# Preparing the data for the fusion model\n",
    "\n",
    "#Resizing images, if needed\n",
    "SIZE_X = 256 #128 \n",
    "SIZE_Y = 256 #128\n",
    "n_classes = 3 #Number of classes for segmentation\n",
    "path1 = os.path.abspath('../')\n",
    "path_training_100x100_image = os.path.join(path1, \"grid_images/train\")\n",
    "path_mask_100x100_image = os.path.join(path1, \"grid_images/mask\")\n",
    "#training image as a list\n",
    "train_images_list = train_images_\n",
    "train_images = []\n",
    "\n",
    "\n",
    "for directory_path in glob.glob(path_training_100x100_image):\n",
    "    for img_path in sorted(glob.glob(os.path.join(directory_path, \"*.png\"))):\n",
    "        if img_path not in train_images_list:\n",
    "            continue\n",
    "        img = cv2.imread(img_path, 0)\n",
    "        if img is None:\n",
    "            print(f\"Warning: Could not load image {img_path}. Skipping.\")\n",
    "            continue\n",
    "        img = cv2.resize(img, (SIZE_Y, SIZE_X))\n",
    "        train_images.append(img)\n",
    "\n",
    "#Convert list to array for machine learning processing\n",
    "train_images = np.array(train_images)\n",
    "\n",
    "#training mask/label as a list\n",
    "mask_images_list = train_masks_\n",
    "train_masks = [] \n",
    "\n",
    "for directory_path in glob.glob(path_mask_100x100_image):\n",
    "    for mask_path in sorted(glob.glob(os.path.join(directory_path, \"*.png\"))):\n",
    "        if mask_path not in mask_images_list:\n",
    "            continue\n",
    "        mask = cv2.imread(mask_path, 0)\n",
    "        mask = cv2.resize(mask, (SIZE_Y, SIZE_X), interpolation = cv2.INTER_NEAREST)  #Otherwise ground truth changes due to interpolation\n",
    "        train_masks.append(mask)\n",
    "#Convert list to array for machine learning processing\n",
    "\n",
    "train_masks = np.array(train_masks)\n",
    "print(np.size(train_masks), np.size(train_images))\n",
    "np.unique(train_masks)\n",
    "print(train_images.shape, train_masks.shape)\n",
    "# plot_image(train_images[1], train_masks[1])\n",
    "\n",
    "###############################################\n",
    "#Encode labels... but multi dim array so need to flatten, encode and reshape\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder = LabelEncoder()\n",
    "n, h, w = train_masks.shape\n",
    "train_masks_reshaped = train_masks.reshape(-1,1)\n",
    "train_masks_reshaped_encoded = labelencoder.fit_transform(train_masks_reshaped)\n",
    "train_masks_encoded_original_shape = train_masks_reshaped_encoded.reshape(n, h, w)\n",
    "\n",
    "np.unique(train_masks_encoded_original_shape)\n",
    "\n",
    "print(\"train image shape\", train_images.shape)\n",
    "print(\"train masks shape\", train_masks.shape)\n",
    "\n",
    "#################################################\n",
    "train_images = np.expand_dims(train_images, axis=3)\n",
    "train_images = normalize(train_images, axis=1)\n",
    "\n",
    "train_masks_input = np.expand_dims(train_masks_encoded_original_shape, axis=3)\n",
    "\n",
    "\n",
    "print()\n",
    "print(\"train image shape\", train_images.shape)\n",
    "print(\"train masks input shape\", train_masks_input.shape)\n",
    "\n",
    "#################################################\n",
    "# Here I take only train_masks_input and comment out the rest of the code\n",
    "#################################################\n",
    "#Selecting 20% for testing and remaining for training\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_unet, X_test_unet, y_train_unet, y_test_unet = train_test_split(train_images, train_masks_input, test_size=0.20, random_state=0)\n",
    "\n",
    "print(\"Class values in the dataset are ... \", np.unique(y_train_unet))\n",
    "\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "train_masks_cat = to_categorical(y_train_unet, num_classes=n_classes)\n",
    "y_train_cat = train_masks_cat.reshape((y_train_unet.shape[0], y_train_unet.shape[1], y_train_unet.shape[2], n_classes))\n",
    "\n",
    "\n",
    "\n",
    "test_masks_cat = to_categorical(y_test_unet, num_classes=n_classes)\n",
    "y_test_cat = test_masks_cat.reshape((y_test_unet.shape[0], y_test_unet.shape[1], y_test_unet.shape[2], n_classes))\n",
    "\n",
    "\n",
    "print(\"X_train_unet train image shape\", X_train_unet.shape)\n",
    "print(\"X_test_unet train image shape\", X_test_unet.shape)\n",
    "print(\"y_train_cat shape\", y_train_cat.shape)\n",
    "print(\"y_test_cat shape\", y_test_cat.shape)\n",
    "\n",
    "# IMG_HEIGHT = X_train.shape[1]\n",
    "# IMG_WIDTH  = X_train.shape[2]\n",
    "# IMG_CHANNELS = X_train.shape[3]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UNet model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get model\n",
    "# history = train_model(\n",
    "#     unet_model,\n",
    "#     X_train_unet,\n",
    "#     y_train_cat,\n",
    "#     X_test_unet,\n",
    "#     y_test_cat,\n",
    "#     epochs=EPOCHS,\n",
    "#     batch_size=BATCH_SIZE\n",
    "# )\n",
    "\n",
    "# # Evaluate the model\n",
    "# test_loss, test_accuracy = evaluate_model(unet_model, X_test_unet, y_test_cat)\n",
    "# print(f\"\\nTest Loss: {test_loss:.4f}\")\n",
    "# print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "# # Plot training history\n",
    "# plot_training_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data cleaning on ATLO3 files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>h_cor_mean-2</th>\n",
       "      <th>height_sd-2</th>\n",
       "      <th>pcnth_mean-2</th>\n",
       "      <th>pcnt_mean-2</th>\n",
       "      <th>h_cor_mean-1</th>\n",
       "      <th>height_sd-1</th>\n",
       "      <th>pcnth_mean-1</th>\n",
       "      <th>pcnt_mean-1</th>\n",
       "      <th>h_cor_mean0</th>\n",
       "      <th>height_sd0</th>\n",
       "      <th>pcnth_mean0</th>\n",
       "      <th>pcnt_mean0</th>\n",
       "      <th>h_cor_mean1</th>\n",
       "      <th>height_sd1</th>\n",
       "      <th>pcnth_mean1</th>\n",
       "      <th>pcnt_mean1</th>\n",
       "      <th>h_cor_mean2</th>\n",
       "      <th>height_sd2</th>\n",
       "      <th>pcnth_mean2</th>\n",
       "      <th>pcnt_mean2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10000</th>\n",
       "      <td>0.791500</td>\n",
       "      <td>0.169983</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>0.971037</td>\n",
       "      <td>0.070724</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>7.400000</td>\n",
       "      <td>0.888939</td>\n",
       "      <td>0.173739</td>\n",
       "      <td>2.714286</td>\n",
       "      <td>8.571429</td>\n",
       "      <td>0.842807</td>\n",
       "      <td>0.186369</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.922513</td>\n",
       "      <td>0.082469</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>6.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10001</th>\n",
       "      <td>0.971037</td>\n",
       "      <td>0.070724</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>7.400000</td>\n",
       "      <td>0.888939</td>\n",
       "      <td>0.173739</td>\n",
       "      <td>2.714286</td>\n",
       "      <td>8.571429</td>\n",
       "      <td>0.842807</td>\n",
       "      <td>0.186369</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.922513</td>\n",
       "      <td>0.082469</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>6.400000</td>\n",
       "      <td>0.796576</td>\n",
       "      <td>0.165304</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>6.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10002</th>\n",
       "      <td>0.888939</td>\n",
       "      <td>0.173739</td>\n",
       "      <td>2.714286</td>\n",
       "      <td>8.571429</td>\n",
       "      <td>0.842807</td>\n",
       "      <td>0.186369</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.922513</td>\n",
       "      <td>0.082469</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>6.400000</td>\n",
       "      <td>0.796576</td>\n",
       "      <td>0.165304</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>6.916667</td>\n",
       "      <td>0.754750</td>\n",
       "      <td>0.127537</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>7.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10003</th>\n",
       "      <td>0.842807</td>\n",
       "      <td>0.186369</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.922513</td>\n",
       "      <td>0.082469</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>6.400000</td>\n",
       "      <td>0.796576</td>\n",
       "      <td>0.165304</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>6.916667</td>\n",
       "      <td>0.754750</td>\n",
       "      <td>0.127537</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>7.333333</td>\n",
       "      <td>0.846794</td>\n",
       "      <td>0.108723</td>\n",
       "      <td>5.888889</td>\n",
       "      <td>7.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10004</th>\n",
       "      <td>0.922513</td>\n",
       "      <td>0.082469</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>6.400000</td>\n",
       "      <td>0.796576</td>\n",
       "      <td>0.165304</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>6.916667</td>\n",
       "      <td>0.754750</td>\n",
       "      <td>0.127537</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>7.333333</td>\n",
       "      <td>0.846794</td>\n",
       "      <td>0.108723</td>\n",
       "      <td>5.888889</td>\n",
       "      <td>7.888889</td>\n",
       "      <td>0.774610</td>\n",
       "      <td>0.110507</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>5.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102965</th>\n",
       "      <td>0.663228</td>\n",
       "      <td>0.700268</td>\n",
       "      <td>5.400000</td>\n",
       "      <td>9.066667</td>\n",
       "      <td>0.511376</td>\n",
       "      <td>0.569917</td>\n",
       "      <td>7.782609</td>\n",
       "      <td>11.304348</td>\n",
       "      <td>0.413798</td>\n",
       "      <td>0.347209</td>\n",
       "      <td>8.680000</td>\n",
       "      <td>12.040000</td>\n",
       "      <td>0.391911</td>\n",
       "      <td>0.271459</td>\n",
       "      <td>5.941176</td>\n",
       "      <td>7.176471</td>\n",
       "      <td>0.490262</td>\n",
       "      <td>0.221304</td>\n",
       "      <td>7.533333</td>\n",
       "      <td>11.466667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102966</th>\n",
       "      <td>0.511376</td>\n",
       "      <td>0.569917</td>\n",
       "      <td>7.782609</td>\n",
       "      <td>11.304348</td>\n",
       "      <td>0.413798</td>\n",
       "      <td>0.347209</td>\n",
       "      <td>8.680000</td>\n",
       "      <td>12.040000</td>\n",
       "      <td>0.391911</td>\n",
       "      <td>0.271459</td>\n",
       "      <td>5.941176</td>\n",
       "      <td>7.176471</td>\n",
       "      <td>0.490262</td>\n",
       "      <td>0.221304</td>\n",
       "      <td>7.533333</td>\n",
       "      <td>11.466667</td>\n",
       "      <td>0.528215</td>\n",
       "      <td>0.321206</td>\n",
       "      <td>9.888889</td>\n",
       "      <td>14.037037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102967</th>\n",
       "      <td>0.413798</td>\n",
       "      <td>0.347209</td>\n",
       "      <td>8.680000</td>\n",
       "      <td>12.040000</td>\n",
       "      <td>0.391911</td>\n",
       "      <td>0.271459</td>\n",
       "      <td>5.941176</td>\n",
       "      <td>7.176471</td>\n",
       "      <td>0.490262</td>\n",
       "      <td>0.221304</td>\n",
       "      <td>7.533333</td>\n",
       "      <td>11.466667</td>\n",
       "      <td>0.528215</td>\n",
       "      <td>0.321206</td>\n",
       "      <td>9.888889</td>\n",
       "      <td>14.037037</td>\n",
       "      <td>0.442396</td>\n",
       "      <td>0.284981</td>\n",
       "      <td>7.363636</td>\n",
       "      <td>8.045455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102968</th>\n",
       "      <td>0.391911</td>\n",
       "      <td>0.271459</td>\n",
       "      <td>5.941176</td>\n",
       "      <td>7.176471</td>\n",
       "      <td>0.490262</td>\n",
       "      <td>0.221304</td>\n",
       "      <td>7.533333</td>\n",
       "      <td>11.466667</td>\n",
       "      <td>0.528215</td>\n",
       "      <td>0.321206</td>\n",
       "      <td>9.888889</td>\n",
       "      <td>14.037037</td>\n",
       "      <td>0.442396</td>\n",
       "      <td>0.284981</td>\n",
       "      <td>7.363636</td>\n",
       "      <td>8.045455</td>\n",
       "      <td>0.473765</td>\n",
       "      <td>0.144270</td>\n",
       "      <td>7.782609</td>\n",
       "      <td>9.869565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102969</th>\n",
       "      <td>0.490262</td>\n",
       "      <td>0.221304</td>\n",
       "      <td>7.533333</td>\n",
       "      <td>11.466667</td>\n",
       "      <td>0.528215</td>\n",
       "      <td>0.321206</td>\n",
       "      <td>9.888889</td>\n",
       "      <td>14.037037</td>\n",
       "      <td>0.442396</td>\n",
       "      <td>0.284981</td>\n",
       "      <td>7.363636</td>\n",
       "      <td>8.045455</td>\n",
       "      <td>0.473765</td>\n",
       "      <td>0.144270</td>\n",
       "      <td>7.782609</td>\n",
       "      <td>9.869565</td>\n",
       "      <td>0.355467</td>\n",
       "      <td>0.145530</td>\n",
       "      <td>9.357143</td>\n",
       "      <td>12.071429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3267 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        h_cor_mean-2  height_sd-2  pcnth_mean-2  pcnt_mean-2  h_cor_mean-1  \\\n",
       "10000       0.791500     0.169983      1.000000     6.500000      0.971037   \n",
       "10001       0.971037     0.070724      3.600000     7.400000      0.888939   \n",
       "10002       0.888939     0.173739      2.714286     8.571429      0.842807   \n",
       "10003       0.842807     0.186369      2.000000     7.000000      0.922513   \n",
       "10004       0.922513     0.082469      1.800000     6.400000      0.796576   \n",
       "...              ...          ...           ...          ...           ...   \n",
       "102965      0.663228     0.700268      5.400000     9.066667      0.511376   \n",
       "102966      0.511376     0.569917      7.782609    11.304348      0.413798   \n",
       "102967      0.413798     0.347209      8.680000    12.040000      0.391911   \n",
       "102968      0.391911     0.271459      5.941176     7.176471      0.490262   \n",
       "102969      0.490262     0.221304      7.533333    11.466667      0.528215   \n",
       "\n",
       "        height_sd-1  pcnth_mean-1  pcnt_mean-1  h_cor_mean0  height_sd0  \\\n",
       "10000      0.070724      3.600000     7.400000     0.888939    0.173739   \n",
       "10001      0.173739      2.714286     8.571429     0.842807    0.186369   \n",
       "10002      0.186369      2.000000     7.000000     0.922513    0.082469   \n",
       "10003      0.082469      1.800000     6.400000     0.796576    0.165304   \n",
       "10004      0.165304      4.166667     6.916667     0.754750    0.127537   \n",
       "...             ...           ...          ...          ...         ...   \n",
       "102965     0.569917      7.782609    11.304348     0.413798    0.347209   \n",
       "102966     0.347209      8.680000    12.040000     0.391911    0.271459   \n",
       "102967     0.271459      5.941176     7.176471     0.490262    0.221304   \n",
       "102968     0.221304      7.533333    11.466667     0.528215    0.321206   \n",
       "102969     0.321206      9.888889    14.037037     0.442396    0.284981   \n",
       "\n",
       "        pcnth_mean0  pcnt_mean0  h_cor_mean1  height_sd1  pcnth_mean1  \\\n",
       "10000      2.714286    8.571429     0.842807    0.186369     2.000000   \n",
       "10001      2.000000    7.000000     0.922513    0.082469     1.800000   \n",
       "10002      1.800000    6.400000     0.796576    0.165304     4.166667   \n",
       "10003      4.166667    6.916667     0.754750    0.127537     4.333333   \n",
       "10004      4.333333    7.333333     0.846794    0.108723     5.888889   \n",
       "...             ...         ...          ...         ...          ...   \n",
       "102965     8.680000   12.040000     0.391911    0.271459     5.941176   \n",
       "102966     5.941176    7.176471     0.490262    0.221304     7.533333   \n",
       "102967     7.533333   11.466667     0.528215    0.321206     9.888889   \n",
       "102968     9.888889   14.037037     0.442396    0.284981     7.363636   \n",
       "102969     7.363636    8.045455     0.473765    0.144270     7.782609   \n",
       "\n",
       "        pcnt_mean1  h_cor_mean2  height_sd2  pcnth_mean2  pcnt_mean2  \n",
       "10000     7.000000     0.922513    0.082469     1.800000    6.400000  \n",
       "10001     6.400000     0.796576    0.165304     4.166667    6.916667  \n",
       "10002     6.916667     0.754750    0.127537     4.333333    7.333333  \n",
       "10003     7.333333     0.846794    0.108723     5.888889    7.888889  \n",
       "10004     7.888889     0.774610    0.110507     2.333333    5.166667  \n",
       "...            ...          ...         ...          ...         ...  \n",
       "102965    7.176471     0.490262    0.221304     7.533333   11.466667  \n",
       "102966   11.466667     0.528215    0.321206     9.888889   14.037037  \n",
       "102967   14.037037     0.442396    0.284981     7.363636    8.045455  \n",
       "102968    8.045455     0.473765    0.144270     7.782609    9.869565  \n",
       "102969    9.869565     0.355467    0.145530     9.357143   12.071429  \n",
       "\n",
       "[3267 rows x 20 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(3267, 5, 4)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# delete all rows in lstm data that are not in available_indices\n",
    "lstm_dataset = dataset_accu.copy()\n",
    "# size before\n",
    "# print(lstm_dataset.shape)\n",
    "lstm_features_synced = lstm_dataset[lstm_dataset['index'].isin(available_indices)]\n",
    "\n",
    "# separate features and labels\n",
    "lstm_labels = lstm_features_synced.pop('label')\n",
    "lstm_features_synced.pop('date')\n",
    "lstm_features_synced.pop('index')\n",
    "lstm_features_synced.pop('lat')\n",
    "lstm_features_synced.pop('lon')\n",
    "display(lstm_features_synced)\n",
    "\n",
    "# normalized the features\n",
    "norm_lstm_features = norm(lstm_features_synced)\n",
    "\n",
    "new_lstm_features = []\n",
    "for row in np_array:\n",
    "  # construct features array\n",
    "  point_r2 =  row[1:5]\n",
    "  point_r1 =  row[5:9]\n",
    "  point_0 = row[9:13]\n",
    "  point_l1 = row[13:17]\n",
    "  point_l2 = row[17:21]\n",
    "  new_lstm_features.append([point_r2, point_r1, point_0, point_l1, point_l2])\n",
    "new_lstm_features = np.array(new_lstm_features)\n",
    "#################################################\n",
    "lstm_labels_multi = convert_to_multi_calss(lstm_labels)\n",
    "new_lstm_features.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clone the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lstm\n",
      "dropout\n",
      "dense\n",
      "dropout_1\n",
      "dense_1\n",
      "dropout_2\n",
      "dense_2\n",
      "dropout_3\n",
      "dense_3\n",
      "dropout_4\n",
      "dense_4\n",
      "dropout_5\n",
      "dense_5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Clone the models with a unique prefix to avoid layer name conflicts\n",
    "unet_model_cloned = clone_model(unet_model)\n",
    "unet_model_cloned.set_weights(unet_model.get_weights())\n",
    "lstm_model_cloned = clone_model(lstm_model)\n",
    "lstm_model_cloned.set_weights(lstm_model.get_weights())\n",
    "\n",
    "# Rename layers to avoid conflicts\n",
    "for layer in unet_model_cloned.layers:\n",
    "    layer.name = \"unet_\" + layer.name\n",
    "\n",
    "for layer in lstm_model_cloned.layers:\n",
    "    print(layer.name)\n",
    "    layer.name = \"lstm_\" + layer.name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the fusion models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get input and output layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unet output <KerasTensor shape=(None, 256, 256, 16), dtype=float32, sparse=False, name=keras_tensor_334>\n",
      "lstm output (None, 16)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "To creates the fusion model we need to understand the shapes of our inputs:\n",
    "- Input of the LSTM model is a 5x4 matrix & is found on the first index of the models layers list.\n",
    "- Input of the UNet model is a 256x256x1 image (Resized from 100x100)\n",
    "\n",
    "- To build the fusion, we will extract the features from the last hidden layer of both models.\n",
    "- We will then flatten the features from the UNet model to match the shape of the LSTM model.\n",
    "\"\"\"\n",
    "\n",
    "# Get the input layers\n",
    "unet_input = unet_model_cloned.input\n",
    "lstm_input = lstm_model_cloned.layers[0].input\n",
    "# Extract features (fusion layers) from the cloned UNet and LSTM models\n",
    "unet_features = unet_model_cloned.layers[-2].output  # Last layer before the output\n",
    "lstm_features = lstm_model_cloned.layers[-2].output  # Last layer before the output\n",
    "\n",
    "# print the shapes of the features\n",
    "print(\"unet output\", unet_features)\n",
    "print(\"lstm output\", lstm_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Center extraction for the UNet and Reshaping of vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before flattening unet output (None, 256, 256, 16)\n",
      "after flattening unet output (None, 16)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def extract_center_pixel(x):\n",
    "    ceter_h = x.shape[1] // 2\n",
    "    ceter_w = x.shape[2] // 2\n",
    "    return x[:, ceter_h, ceter_w, :]\n",
    "\n",
    "# Flatten the vectors and ready the layers in the middle\n",
    "unet_center = Lambda(extract_center_pixel)(unet_features)  # Shape: (None, 1, 1, 16)\n",
    "unet_features_flat = Reshape((16,))(unet_center)  # Shape: (None, 16)\n",
    "print(\"before flattening unet output\", unet_features.shape)\n",
    "print(\"after flattening unet output\", unet_features_flat.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multimodals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EYE mtrx for missing modality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_missing_with_identity(input_data, expected_shape):\n",
    "    \"\"\"\n",
    "    Replace missing input data (None) with an identity matrix of the appropriate shape.\n",
    "    \"\"\"\n",
    "    if input_data is None:\n",
    "        # Create an identity matrix for the feature dimensions\n",
    "        batch_size = expected_shape[0]  # Use batch size from input if available\n",
    "        features_dim = expected_shape[-1]\n",
    "        # Create an identity matrix and tile to match the batch size\n",
    "        identity_matrix = np.eye(features_dim)\n",
    "        identity_matrix = np.tile(identity_matrix, (batch_size, 1))\n",
    "        return identity_matrix  # Return as a NumPy array\n",
    "    return input_data  # Ensure this is a NumPy array\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zero padding for missing modality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import ZeroPadding1D\n",
    "\n",
    "# If input is None, use zeros for padding\n",
    "def replace_missing_with_zeros(input_tensor, expected_shape):\n",
    "    if input_tensor is None:\n",
    "        return tf.zeros(shape=expected_shape, dtype=tf.float32)\n",
    "    return input_tensor\n",
    "\n",
    "# Replace missing input with zeros instead\n",
    "unet_input = replace_missing_with_zeros(unet_input, expected_shape=(BATCH_SIZE, unet_input.shape[-1]))\n",
    "lstm_input = replace_missing_with_zeros(lstm_input, expected_shape=(BATCH_SIZE, lstm_input.shape[-1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model for multiplication fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's output shape (None, 3)\n",
      "Expected input shape:  [(None, 256, 256, 1), (None, 5, 4)]\n",
      "Expected output shape:  (None, 3)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "############################################################################################################\n",
    "###########                      MULTIPLICATIVE FUSION                                         #############\n",
    "############################################################################################################\n",
    "\"\"\"\n",
    "# from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Multiplicative fusion\n",
    "multiplicative_fused_features = Multiply()([unet_features_flat, lstm_features])\n",
    "\n",
    "# Add a dense layer for final classification\n",
    "x = BatchNormalization()(multiplicative_fused_features)\n",
    "\n",
    "# 2. Implement a deeper network with residual connections\n",
    "x1 = Dense(64, activation='relu')(x)\n",
    "x1 = Dropout(0.3)(x1)\n",
    "x1 = BatchNormalization()(x1)\n",
    "\n",
    "# Second branch - keep same dimensions for residual connection\n",
    "x2 = Dense(64, activation='relu')(x1)\n",
    "x2 = Dropout(0.2)(x2)\n",
    "x2 = BatchNormalization()(x2)\n",
    "\n",
    "# Now the shapes match for the residual connection\n",
    "x = tf.keras.layers.Add()([x1, x2])\n",
    "\n",
    "# Final classification layers\n",
    "x = Dense(32, activation='relu')(x)\n",
    "x = Dropout(0.1)(x)\n",
    "multiplicative_output = Dense(3, activation='softmax')(x)\n",
    "\n",
    "print(\"Model's output shape\", multiplicative_output.shape)\n",
    "\n",
    "# Create the fusion model\n",
    "multiplicative_fusion_model = Model(\n",
    "    inputs=[unet_input, lstm_input],\n",
    "    outputs=multiplicative_output\n",
    ")\n",
    "\n",
    "# Print model's expected input shape and output shape\n",
    "print(\"Expected input shape: \", multiplicative_fusion_model.input_shape)\n",
    "print(\"Expected output shape: \", multiplicative_fusion_model.output_shape)\n",
    "\n",
    "initial_learning_rate = 0.001\n",
    "optimizer = Adam(\n",
    "    learning_rate=initial_learning_rate,\n",
    "    beta_1=0.9,\n",
    "    beta_2=0.999,\n",
    "    epsilon=1e-07\n",
    ")\n",
    "\n",
    "\n",
    "def build_mlf_model(learning_rate=0.001, dropout1=0.3, dropout2=0.2, dropout3=0.1):\n",
    "    # Add a dense layer for final classification\n",
    "    x = BatchNormalization()(multiplicative_fused_features)\n",
    "\n",
    "    x1 = Dense(64, activation='relu')(x)\n",
    "    x1 = Dropout(dropout1)(x1)\n",
    "    x1 = BatchNormalization()(x1)\n",
    "\n",
    "    x2 = Dense(64, activation='relu')(x1)\n",
    "    x2 = Dropout(dropout2)(x2)\n",
    "    x2 = BatchNormalization()(x2)\n",
    "\n",
    "    x = tf.keras.layers.Add()([x1, x2])\n",
    "\n",
    "    x = Dense(32, activation='relu')(x)\n",
    "    x = Dropout(dropout3)(x)\n",
    "    multiplicative_output = Dense(3, activation='softmax')(x)\n",
    "\n",
    "    # Create the fusion model\n",
    "    mlf_model = Model(\n",
    "        inputs=[unet_input, lstm_input],\n",
    "        outputs=multiplicative_output\n",
    "    )\n",
    "\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    mlf_model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=[\n",
    "            'accuracy', \n",
    "            tf.keras.metrics.AUC(), \n",
    "            tf.keras.metrics.Precision(), \n",
    "            tf.keras.metrics.Recall()\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return mlf_model\n",
    "\n",
    "# Compile the fusion model\n",
    "multiplicative_fusion_model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=[\n",
    "        'accuracy',\n",
    "        tf.keras.metrics.AUC(),\n",
    "        tf.keras.metrics.Precision(),\n",
    "        tf.keras.metrics.Recall()\n",
    "    ]\n",
    ")\n",
    "\n",
    "# show the model architecture\n",
    "# plot_model(\n",
    "#     multiplicative_fusion_model, \n",
    "#     to_file='model.png', \n",
    "#     show_shapes=True, \n",
    "#     show_layer_names=False, \n",
    "#     rankdir='TB', \n",
    "#     expand_nested=False, \n",
    "#     dpi=96\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model for additive fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's output shape (None, 3)\n",
      "Expected input shape:  [(None, 256, 256, 1), (None, 5, 4)]\n",
      "Expected output shape:  (None, 3)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "############################################################################################################\n",
    "###########                      ADDITIVE FUSION                                         ###################        \n",
    "############################################################################################################\n",
    "\"\"\"\n",
    "\n",
    "# Additive fusion\n",
    "additive_fused_features = Concatenate()([unet_features_flat, lstm_features])\n",
    "\n",
    "# Add a dense layer for final classification\n",
    "\n",
    "x = BatchNormalization()(additive_fused_features)\n",
    "\n",
    "# 2. Implement a deeper network with residual connections\n",
    "x1 = Dense(64, activation='relu')(x)\n",
    "x1 = Dropout(0.3)(x1)\n",
    "x1 = BatchNormalization()(x1)\n",
    "\n",
    "# Second branch - keep same dimensions for residual connection\n",
    "x2 = Dense(64, activation='relu')(x1)\n",
    "x2 = Dropout(0.2)(x2)\n",
    "x2 = BatchNormalization()(x2)\n",
    "\n",
    "# Now the shapes match for the residual connection\n",
    "x = tf.keras.layers.Add()([x1, x2])\n",
    "\n",
    "# Final classification layers\n",
    "x = Dense(32, activation='relu')(x)\n",
    "x = Dropout(0.1)(x)\n",
    "additive_output = Dense(3, activation='softmax')(x)\n",
    "print(\"Model's output shape\", additive_output.shape)\n",
    "\n",
    "\n",
    "# Create the fusion model\n",
    "additive_fusion_model = Model(\n",
    "    inputs=[unet_input, lstm_input],\n",
    "    outputs=additive_output\n",
    ")\n",
    "\n",
    "# Print model's expected input shape and output shape\n",
    "print(\"Expected input shape: \", additive_fusion_model.input_shape)\n",
    "print(\"Expected output shape: \", additive_fusion_model.output_shape)\n",
    "\n",
    "initial_learning_rate = 0.001\n",
    "optimizer_af = Adam(\n",
    "    learning_rate=initial_learning_rate,\n",
    "    beta_1=0.9,\n",
    "    beta_2=0.999,\n",
    "    epsilon=1e-07\n",
    ")\n",
    "\n",
    "# Compile the fusion model\n",
    "additive_fusion_model.compile(\n",
    "    optimizer=optimizer_af,\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=[\n",
    "        'accuracy',\n",
    "        tf.keras.metrics.AUC(),\n",
    "        tf.keras.metrics.Precision(),\n",
    "        tf.keras.metrics.Recall()\n",
    "    ]\n",
    ")\n",
    "\n",
    "# show the model architecture\n",
    "# plot_model(additive_fusion_model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model for Gated fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's output shape (None, 3)\n",
      "Expected input shape:  [(None, 256, 256, 1), (None, 5, 4)]\n",
      "Expected output shape:  (None, 3)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "############################################################################################################\n",
    "###########                                 GATED FUSION                                       #############        \n",
    "############################################################################################################\n",
    "\"\"\"\n",
    "# Transform the lstm_features to match the shape of the unet_features_flat\n",
    "# lstm_features_transformed = Dense(unet_features_flat.shape[-1])(lstm_features)\n",
    "\n",
    "gate = Dense(unet_features_flat.shape[-1], activation='sigmoid')(Concatenate()([unet_features_flat, lstm_features]))\n",
    "\n",
    "# Apply the gate to the features\n",
    "gated_unet_features = Multiply()([unet_features_flat, gate])\n",
    "gated_lstm_features = Multiply()([lstm_features, 1 - gate])\n",
    "\n",
    "# Combine the gated features\n",
    "gated_fused_features = Concatenate()([gated_unet_features, gated_lstm_features])\n",
    "\n",
    "# Add a dense layer for final classification\n",
    "\n",
    "x = BatchNormalization()(gated_fused_features)\n",
    "\n",
    "# 2. Implement a deeper network with residual connections\n",
    "x1 = Dense(64, activation='relu')(x)\n",
    "x1 = Dropout(0.3)(x1)\n",
    "x1 = BatchNormalization()(x1)\n",
    "\n",
    "# Second branch - keep same dimensions for residual connection\n",
    "x2 = Dense(64, activation='relu')(x1)\n",
    "x2 = Dropout(0.2)(x2)\n",
    "x2 = BatchNormalization()(x2)\n",
    "\n",
    "# Now the shapes match for the residual connection\n",
    "x = tf.keras.layers.Add()([x1, x2])\n",
    "\n",
    "# Final classification layers\n",
    "x = Dense(32, activation='relu')(x)\n",
    "x = Dropout(0.1)(x)\n",
    "gated_output = Dense(3, activation='softmax')(x)\n",
    "print(\"Model's output shape\", gated_output.shape)\n",
    "\n",
    "# Create the fusion model\n",
    "gated_fusion_model = Model(\n",
    "    inputs=[unet_input, lstm_input],\n",
    "    outputs=gated_output\n",
    ")\n",
    "\n",
    "# Print model's expected input shape and output shape\n",
    "print(\"Expected input shape: \", gated_fusion_model.input_shape)\n",
    "print(\"Expected output shape: \", gated_fusion_model.output_shape)\n",
    "initial_learning_rate = 0.001\n",
    "optimizer_gf = Adam(\n",
    "    learning_rate=initial_learning_rate,\n",
    "    beta_1=0.9,\n",
    "    beta_2=0.999,\n",
    "    epsilon=1e-07\n",
    ")\n",
    "# Compile the fusion model\n",
    "gated_fusion_model.compile(\n",
    "    optimizer=optimizer_gf,\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=[\n",
    "        'accuracy',\n",
    "        tf.keras.metrics.AUC(),\n",
    "        tf.keras.metrics.Precision(),\n",
    "        tf.keras.metrics.Recall()\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final splitting of the data and visualizing the shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3267, 256, 256, 1)\n",
      "(3267, 256, 256, 1)\n",
      "(3267, 5, 4)\n",
      "(3267, 3)\n",
      "Before categorical conversion\n",
      "X_train_lstm (2613, 5, 4)\n",
      "X_test_lstm (654, 5, 4)\n",
      "Y_train (2613, 3)\n",
      "Y_test (654, 3)\n",
      "masks_train (2613, 256, 256, 1)\n",
      "masks_test (654, 256, 256, 1)\n",
      "Class values in the dataset are ...  [0 1 2]\n",
      "##########\n",
      "After categorical conversion\n",
      "X_train_unet train image shape (2613, 256, 256, 1)\n",
      "X_test_unet train image shape (654, 256, 256, 1)\n",
      "y_train_cat shape (2613, 256, 256, 3)\n",
      "y_test_cat shape (654, 256, 256, 3)\n"
     ]
    }
   ],
   "source": [
    "# print sizes of all train_images, new_lstm_features, lstm_labels_multi\n",
    "print(train_images.shape) # (835, 256, 256, 1)\n",
    "print(train_masks_input.shape) # (835, 256, 256, 1) this is the label for the unet model\n",
    "print(new_lstm_features.shape) # (835, 5, 4)\n",
    "print(lstm_labels_multi.shape) # (835, 3)\n",
    "\n",
    "\n",
    "# (1632, 256, 256, 1)\n",
    "# (1632, 256, 256, 1)\n",
    "# (1616, 5, 4)\n",
    "# (1632, 3)\n",
    "\n",
    "X_train_unet, X_test_unet, X_train_lstm, X_test_lstm, Y_train, Y_test, masks_train, masks_test = train_test_split(\n",
    "    train_images, new_lstm_features, lstm_labels_multi, train_masks_input, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# print sizes of all X_train_unet, X_test_unet, X_train_lstm, X_test_lstm, Y_train, Y_test\n",
    "print(\"Before categorical conversion\")\n",
    "print(\"X_train_lstm\", X_train_lstm.shape) \n",
    "print(\"X_test_lstm\", X_test_lstm.shape)\n",
    "print(\"Y_train\", Y_train.shape) # (668, 3)\n",
    "print(\"Y_test\", Y_test.shape) # (167, 3)\n",
    "print(\"masks_train\", masks_train.shape)\n",
    "print(\"masks_test\", masks_test.shape)\n",
    "print(\"Class values in the dataset are ... \", np.unique(masks_train))\n",
    "\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "train_masks_cat = to_categorical(masks_train, num_classes=n_classes)\n",
    "y_train_cat = train_masks_cat.reshape((masks_train.shape[0], masks_train.shape[1], masks_train.shape[2], n_classes))\n",
    "\n",
    "\n",
    "test_masks_cat = to_categorical(masks_test, num_classes=n_classes)\n",
    "y_test_cat = test_masks_cat.reshape((masks_test.shape[0], masks_test.shape[1], masks_test.shape[2], n_classes))\n",
    "\n",
    "print(\"##########\")\n",
    "print(\"After categorical conversion\")\n",
    "print(\"X_train_unet train image shape\", X_train_unet.shape) # (668, 256, 256, 1)\n",
    "print(\"X_test_unet train image shape\", X_test_unet.shape) # (167, 256, 256, 1)\n",
    "print(\"y_train_cat shape\", y_train_cat.shape) # (668, 256, 256, 3)\n",
    "print(\"y_test_cat shape\", y_test_cat.shape) # (167, 256, 256, 3)\n",
    "\n",
    "# print(\"##############################################\")\n",
    "# print(f\"Shape of X_train_lstm: {X_train_lstm.shape}\")\n",
    "# print(f\"Shape of X_test_lstm: {X_test_lstm.shape}\")\n",
    "# # # Replace missing data for training set\n",
    "# X_train_lstm = replace_missing_with_identity(None, expected_shape=(X_train_lstm.shape[0], X_train_lstm.shape[-1]))\n",
    "# # # X_train_lstm = replace_missing_with_identity(X_train_lstm, (X_train_lstm.shape[0], lstm_features_dim))\n",
    "\n",
    "# # # Replace missing data for validation set\n",
    "# X_test_lstm = replace_missing_with_identity(None, expected_shape=(X_test_lstm.shape[0], X_test_lstm.shape[-1]))\n",
    "# # X_val_lstm = replace_missing_with_identity(X_val_lstm, (X_val_lstm.shape[0], lstm_features_dim))\n",
    "# print(f\"Shape of X_train_lstm: {X_train_lstm.shape}\")\n",
    "# print(f\"Shape of X_test_lstm: {X_test_lstm.shape}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing GF with missing models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train_lstm: (2613, 5, 4)\n",
      "Shape of X_test_lstm: (654, 5, 4)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X_train_lstm_' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape of X_train_lstm: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX_train_lstm\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape of X_test_lstm: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX_test_lstm\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape of new X_train_lstm_: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mX_train_lstm_\u001b[49m\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape of new X_test_lstm_: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX_test_lstm_\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      9\u001b[0m history \u001b[38;5;241m=\u001b[39m train_fusion_model(\n\u001b[1;32m     10\u001b[0m     gated_fusion_model,\n\u001b[1;32m     11\u001b[0m     X_train_unet_,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     17\u001b[0m     epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m\n\u001b[1;32m     18\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train_lstm_' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# make X_train_lstm and X_test_lstm to have an identity matrix without using the replace_missing_with_identity function\n",
    "X_train_unet_ = create_zero_padded_image_tensor(X_train_unet.shape)\n",
    "X_test_unet_ = create_zero_padded_image_tensor(X_test_unet.shape)\n",
    "print(f\"Shape of X_train_lstm: {X_train_lstm.shape}\")\n",
    "print(f\"Shape of X_test_lstm: {X_test_lstm.shape}\")\n",
    "print(f\"Shape of new X_train_lstm_: {X_train_lstm_.shape}\")\n",
    "print(f\"Shape of new X_test_lstm_: {X_test_lstm_.shape}\")\n",
    "\n",
    "history = train_fusion_model(\n",
    "    gated_fusion_model,\n",
    "    X_train_unet_,\n",
    "    X_train_lstm,\n",
    "    Y_train,\n",
    "    X_test_unet_,\n",
    "    X_test_lstm,\n",
    "    Y_test,\n",
    "    epochs=50\n",
    ")\n",
    "\n",
    "# Plot training\n",
    "plot_training_history(history)\n",
    "\n",
    "# # Evaluate the model\n",
    "evaluate_fusion_model(\n",
    "    gated_fusion_model,\n",
    "    X_test_unet_,\n",
    "    X_test_lstm,\n",
    "    Y_test\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# # Sizes of the training and testing sets\n",
    "# train_unet_size = X_train_unet.shape[0]\n",
    "# test_unet_size = X_test_unet.shape[0]\n",
    "# train_lstm_size = X_train_lstm.shape[0]\n",
    "# test_lstm_size = X_test_lstm.shape[0]\n",
    "\n",
    "# # Create a bar chart\n",
    "# labels = ['Train UNet', 'Test UNet', 'Train LSTM', 'Test LSTM']\n",
    "# sizes = [train_unet_size, test_unet_size, train_lstm_size, test_lstm_size]\n",
    "\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.bar(labels, sizes, color=['blue', 'orange', 'green', 'red'])\n",
    "# plt.xlabel('Dataset Split')\n",
    "# plt.ylabel('Number of Samples')\n",
    "# plt.title('Dataset Split Visualization')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the fusion models: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multiplicative Fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# \"\"\"\n",
    "# Train the fusion model with the UNet and LSTM features and considering the output of the LSTM and UNet models\n",
    "# \"\"\"\n",
    "\n",
    "# print(\"Given input shape: \", [X_train_unet.shape, X_train_lstm.shape])\n",
    "# print(\"Given output shape: \", Y_train.shape)\n",
    "# # Train the multiplicative fusion model\n",
    "\n",
    "# history = train_fusion_model(\n",
    "#     multiplicative_fusion_model,\n",
    "#     X_train_unet,\n",
    "#     X_train_lstm,\n",
    "#     Y_train,\n",
    "#     X_test_unet,\n",
    "#     X_test_lstm,\n",
    "#     Y_test,\n",
    "#     epochs=50,\n",
    "# )\n",
    "\n",
    "# # Plot training\n",
    "# plot_training_history(history)\n",
    "\n",
    "# # Evaluate the model\n",
    "# evaluate_fusion_model(\n",
    "#     multiplicative_fusion_model,\n",
    "#     X_test_unet,\n",
    "#     X_test_lstm,\n",
    "#     Y_test\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additive Fusion (Concatenation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6292 - auc_1: 0.7998 - loss: 0.8729 - precision_1: 0.6444 - recall_1: 0.5912\n",
      "Epoch 1: val_loss improved from inf to 0.30098, saving model to best_mlf_model.keras\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m302s\u001b[0m 2s/step - accuracy: 0.6303 - auc_1: 0.8006 - loss: 0.8708 - precision_1: 0.6455 - recall_1: 0.5924 - val_accuracy: 0.9358 - val_auc_1: 0.9680 - val_loss: 0.3010 - val_precision_1: 0.9358 - val_recall_1: 0.9358 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.9277 - auc_1: 0.9767 - loss: 0.2530 - precision_1: 0.9301 - recall_1: 0.9264\n",
      "Epoch 2: val_loss improved from 0.30098 to 0.28928, saving model to best_mlf_model.keras\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m880s\u001b[0m 5s/step - accuracy: 0.9276 - auc_1: 0.9766 - loss: 0.2532 - precision_1: 0.9301 - recall_1: 0.9263 - val_accuracy: 0.9358 - val_auc_1: 0.9617 - val_loss: 0.2893 - val_precision_1: 0.9358 - val_recall_1: 0.9358 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9164 - auc_1: 0.9636 - loss: 0.3155 - precision_1: 0.9167 - recall_1: 0.9152\n",
      "Epoch 3: val_loss improved from 0.28928 to 0.20602, saving model to best_mlf_model.keras\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m264s\u001b[0m 2s/step - accuracy: 0.9164 - auc_1: 0.9637 - loss: 0.3153 - precision_1: 0.9167 - recall_1: 0.9152 - val_accuracy: 0.9358 - val_auc_1: 0.9843 - val_loss: 0.2060 - val_precision_1: 0.9372 - val_recall_1: 0.9358 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9288 - auc_1: 0.9808 - loss: 0.2313 - precision_1: 0.9294 - recall_1: 0.9278\n",
      "Epoch 4: val_loss did not improve from 0.20602\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m267s\u001b[0m 2s/step - accuracy: 0.9288 - auc_1: 0.9808 - loss: 0.2314 - precision_1: 0.9294 - recall_1: 0.9278 - val_accuracy: 0.9358 - val_auc_1: 0.9882 - val_loss: 0.2241 - val_precision_1: 0.9358 - val_recall_1: 0.9358 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9393 - auc_1: 0.9779 - loss: 0.2344 - precision_1: 0.9398 - recall_1: 0.9393\n",
      "Epoch 5: val_loss did not improve from 0.20602\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m354s\u001b[0m 2s/step - accuracy: 0.9392 - auc_1: 0.9779 - loss: 0.2344 - precision_1: 0.9397 - recall_1: 0.9392 - val_accuracy: 0.9358 - val_auc_1: 0.9806 - val_loss: 0.2352 - val_precision_1: 0.9358 - val_recall_1: 0.9358 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9348 - auc_1: 0.9802 - loss: 0.2268 - precision_1: 0.9348 - recall_1: 0.9348\n",
      "Epoch 6: val_loss improved from 0.20602 to 0.18060, saving model to best_mlf_model.keras\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m956s\u001b[0m 6s/step - accuracy: 0.9348 - auc_1: 0.9802 - loss: 0.2268 - precision_1: 0.9348 - recall_1: 0.9348 - val_accuracy: 0.9358 - val_auc_1: 0.9904 - val_loss: 0.1806 - val_precision_1: 0.9358 - val_recall_1: 0.9358 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9339 - auc_1: 0.9825 - loss: 0.2192 - precision_1: 0.9344 - recall_1: 0.9339\n",
      "Epoch 7: val_loss did not improve from 0.18060\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m275s\u001b[0m 2s/step - accuracy: 0.9339 - auc_1: 0.9825 - loss: 0.2193 - precision_1: 0.9344 - recall_1: 0.9339 - val_accuracy: 0.9358 - val_auc_1: 0.9823 - val_loss: 0.2293 - val_precision_1: 0.9358 - val_recall_1: 0.9358 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9362 - auc_1: 0.9787 - loss: 0.2326 - precision_1: 0.9362 - recall_1: 0.9362\n",
      "Epoch 8: val_loss improved from 0.18060 to 0.18044, saving model to best_mlf_model.keras\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m281s\u001b[0m 2s/step - accuracy: 0.9362 - auc_1: 0.9787 - loss: 0.2326 - precision_1: 0.9362 - recall_1: 0.9362 - val_accuracy: 0.9373 - val_auc_1: 0.9873 - val_loss: 0.1804 - val_precision_1: 0.9373 - val_recall_1: 0.9373 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9349 - auc_1: 0.9866 - loss: 0.1932 - precision_1: 0.9352 - recall_1: 0.9349\n",
      "Epoch 9: val_loss improved from 0.18044 to 0.17376, saving model to best_mlf_model.keras\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m267s\u001b[0m 2s/step - accuracy: 0.9349 - auc_1: 0.9866 - loss: 0.1932 - precision_1: 0.9352 - recall_1: 0.9349 - val_accuracy: 0.9511 - val_auc_1: 0.9888 - val_loss: 0.1738 - val_precision_1: 0.9510 - val_recall_1: 0.9495 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9371 - auc_1: 0.9837 - loss: 0.2066 - precision_1: 0.9371 - recall_1: 0.9369\n",
      "Epoch 10: val_loss improved from 0.17376 to 0.15270, saving model to best_mlf_model.keras\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m329s\u001b[0m 2s/step - accuracy: 0.9371 - auc_1: 0.9837 - loss: 0.2066 - precision_1: 0.9371 - recall_1: 0.9369 - val_accuracy: 0.9495 - val_auc_1: 0.9915 - val_loss: 0.1527 - val_precision_1: 0.9495 - val_recall_1: 0.9495 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9326 - auc_1: 0.9849 - loss: 0.2036 - precision_1: 0.9326 - recall_1: 0.9326\n",
      "Epoch 11: val_loss did not improve from 0.15270\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m289s\u001b[0m 2s/step - accuracy: 0.9326 - auc_1: 0.9849 - loss: 0.2036 - precision_1: 0.9326 - recall_1: 0.9326 - val_accuracy: 0.1590 - val_auc_1: 0.5721 - val_loss: 1.1648 - val_precision_1: 0.1590 - val_recall_1: 0.1590 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9323 - auc_1: 0.9790 - loss: 0.2333 - precision_1: 0.9323 - recall_1: 0.9323\n",
      "Epoch 12: val_loss did not improve from 0.15270\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m268s\u001b[0m 2s/step - accuracy: 0.9323 - auc_1: 0.9790 - loss: 0.2332 - precision_1: 0.9323 - recall_1: 0.9323 - val_accuracy: 0.1162 - val_auc_1: 0.5539 - val_loss: 1.6689 - val_precision_1: 0.1162 - val_recall_1: 0.1162 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9430 - auc_1: 0.9859 - loss: 0.1904 - precision_1: 0.9436 - recall_1: 0.9430\n",
      "Epoch 13: val_loss did not improve from 0.15270\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m296s\u001b[0m 2s/step - accuracy: 0.9430 - auc_1: 0.9859 - loss: 0.1905 - precision_1: 0.9435 - recall_1: 0.9430 - val_accuracy: 0.9373 - val_auc_1: 0.9912 - val_loss: 0.1968 - val_precision_1: 0.9372 - val_recall_1: 0.9358 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9422 - auc_1: 0.9872 - loss: 0.1797 - precision_1: 0.9427 - recall_1: 0.9422\n",
      "Epoch 14: val_loss did not improve from 0.15270\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m299s\u001b[0m 2s/step - accuracy: 0.9422 - auc_1: 0.9872 - loss: 0.1797 - precision_1: 0.9427 - recall_1: 0.9422 - val_accuracy: 0.9541 - val_auc_1: 0.9917 - val_loss: 0.1529 - val_precision_1: 0.9541 - val_recall_1: 0.9541 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9333 - auc_1: 0.9870 - loss: 0.1957 - precision_1: 0.9338 - recall_1: 0.9333\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.15270\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m296s\u001b[0m 2s/step - accuracy: 0.9333 - auc_1: 0.9871 - loss: 0.1956 - precision_1: 0.9338 - recall_1: 0.9333 - val_accuracy: 0.9388 - val_auc_1: 0.9888 - val_loss: 0.1849 - val_precision_1: 0.9388 - val_recall_1: 0.9388 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9456 - auc_1: 0.9886 - loss: 0.1744 - precision_1: 0.9456 - recall_1: 0.9456\n",
      "Epoch 16: val_loss did not improve from 0.15270\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2260s\u001b[0m 14s/step - accuracy: 0.9456 - auc_1: 0.9886 - loss: 0.1743 - precision_1: 0.9456 - recall_1: 0.9456 - val_accuracy: 0.9450 - val_auc_1: 0.9857 - val_loss: 0.1858 - val_precision_1: 0.9450 - val_recall_1: 0.9450 - learning_rate: 5.0000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9437 - auc_1: 0.9900 - loss: 0.1641 - precision_1: 0.9437 - recall_1: 0.9437\n",
      "Epoch 17: val_loss did not improve from 0.15270\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m302s\u001b[0m 2s/step - accuracy: 0.9437 - auc_1: 0.9900 - loss: 0.1641 - precision_1: 0.9437 - recall_1: 0.9437 - val_accuracy: 0.9495 - val_auc_1: 0.9897 - val_loss: 0.1804 - val_precision_1: 0.9495 - val_recall_1: 0.9495 - learning_rate: 5.0000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9575 - auc_1: 0.9908 - loss: 0.1501 - precision_1: 0.9575 - recall_1: 0.9575\n",
      "Epoch 18: val_loss improved from 0.15270 to 0.12752, saving model to best_mlf_model.keras\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m285s\u001b[0m 2s/step - accuracy: 0.9575 - auc_1: 0.9908 - loss: 0.1502 - precision_1: 0.9575 - recall_1: 0.9574 - val_accuracy: 0.9648 - val_auc_1: 0.9940 - val_loss: 0.1275 - val_precision_1: 0.9648 - val_recall_1: 0.9648 - learning_rate: 5.0000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9574 - auc_1: 0.9907 - loss: 0.1458 - precision_1: 0.9574 - recall_1: 0.9574\n",
      "Epoch 19: val_loss did not improve from 0.12752\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m287s\u001b[0m 2s/step - accuracy: 0.9574 - auc_1: 0.9907 - loss: 0.1458 - precision_1: 0.9574 - recall_1: 0.9574 - val_accuracy: 0.9587 - val_auc_1: 0.9921 - val_loss: 0.1427 - val_precision_1: 0.9587 - val_recall_1: 0.9587 - learning_rate: 5.0000e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9558 - auc_1: 0.9905 - loss: 0.1402 - precision_1: 0.9558 - recall_1: 0.9558\n",
      "Epoch 20: val_loss did not improve from 0.12752\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m290s\u001b[0m 2s/step - accuracy: 0.9558 - auc_1: 0.9905 - loss: 0.1403 - precision_1: 0.9558 - recall_1: 0.9558 - val_accuracy: 0.9664 - val_auc_1: 0.9926 - val_loss: 0.1331 - val_precision_1: 0.9664 - val_recall_1: 0.9664 - learning_rate: 5.0000e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9438 - auc_1: 0.9888 - loss: 0.1682 - precision_1: 0.9438 - recall_1: 0.9438\n",
      "Epoch 21: val_loss did not improve from 0.12752\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m286s\u001b[0m 2s/step - accuracy: 0.9439 - auc_1: 0.9888 - loss: 0.1681 - precision_1: 0.9439 - recall_1: 0.9439 - val_accuracy: 0.9480 - val_auc_1: 0.9932 - val_loss: 0.1656 - val_precision_1: 0.9480 - val_recall_1: 0.9480 - learning_rate: 5.0000e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9325 - auc_1: 0.9854 - loss: 0.2031 - precision_1: 0.9325 - recall_1: 0.9325\n",
      "Epoch 22: val_loss did not improve from 0.12752\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m293s\u001b[0m 2s/step - accuracy: 0.9325 - auc_1: 0.9855 - loss: 0.2030 - precision_1: 0.9325 - recall_1: 0.9325 - val_accuracy: 0.9495 - val_auc_1: 0.9907 - val_loss: 0.1623 - val_precision_1: 0.9495 - val_recall_1: 0.9495 - learning_rate: 5.0000e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9460 - auc_1: 0.9880 - loss: 0.1727 - precision_1: 0.9460 - recall_1: 0.9460\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 23: val_loss did not improve from 0.12752\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m392s\u001b[0m 2s/step - accuracy: 0.9460 - auc_1: 0.9880 - loss: 0.1726 - precision_1: 0.9460 - recall_1: 0.9460 - val_accuracy: 0.9557 - val_auc_1: 0.9922 - val_loss: 0.1432 - val_precision_1: 0.9557 - val_recall_1: 0.9557 - learning_rate: 5.0000e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9460 - auc_1: 0.9912 - loss: 0.1551 - precision_1: 0.9460 - recall_1: 0.9460\n",
      "Epoch 24: val_loss did not improve from 0.12752\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m273s\u001b[0m 2s/step - accuracy: 0.9460 - auc_1: 0.9912 - loss: 0.1551 - precision_1: 0.9460 - recall_1: 0.9460 - val_accuracy: 0.9587 - val_auc_1: 0.9935 - val_loss: 0.1456 - val_precision_1: 0.9587 - val_recall_1: 0.9587 - learning_rate: 2.5000e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9540 - auc_1: 0.9917 - loss: 0.1445 - precision_1: 0.9540 - recall_1: 0.9540\n",
      "Epoch 25: val_loss did not improve from 0.12752\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m266s\u001b[0m 2s/step - accuracy: 0.9540 - auc_1: 0.9917 - loss: 0.1444 - precision_1: 0.9540 - recall_1: 0.9540 - val_accuracy: 0.9618 - val_auc_1: 0.9902 - val_loss: 0.1426 - val_precision_1: 0.9618 - val_recall_1: 0.9618 - learning_rate: 2.5000e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9668 - auc_1: 0.9931 - loss: 0.1186 - precision_1: 0.9668 - recall_1: 0.9668\n",
      "Epoch 26: val_loss did not improve from 0.12752\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m306s\u001b[0m 2s/step - accuracy: 0.9668 - auc_1: 0.9931 - loss: 0.1186 - precision_1: 0.9668 - recall_1: 0.9668 - val_accuracy: 0.9587 - val_auc_1: 0.9925 - val_loss: 0.1396 - val_precision_1: 0.9587 - val_recall_1: 0.9587 - learning_rate: 2.5000e-04\n",
      "Epoch 27/50\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9690 - auc_1: 0.9926 - loss: 0.1156 - precision_1: 0.9697 - recall_1: 0.9686\n",
      "Epoch 27: val_loss did not improve from 0.12752\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m283s\u001b[0m 2s/step - accuracy: 0.9689 - auc_1: 0.9926 - loss: 0.1157 - precision_1: 0.9696 - recall_1: 0.9685 - val_accuracy: 0.9602 - val_auc_1: 0.9867 - val_loss: 0.1643 - val_precision_1: 0.9602 - val_recall_1: 0.9602 - learning_rate: 2.5000e-04\n",
      "Epoch 28/50\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9585 - auc_1: 0.9912 - loss: 0.1377 - precision_1: 0.9585 - recall_1: 0.9585\n",
      "Epoch 28: val_loss improved from 0.12752 to 0.11419, saving model to best_mlf_model.keras\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m265s\u001b[0m 2s/step - accuracy: 0.9585 - auc_1: 0.9912 - loss: 0.1376 - precision_1: 0.9585 - recall_1: 0.9585 - val_accuracy: 0.9709 - val_auc_1: 0.9936 - val_loss: 0.1142 - val_precision_1: 0.9709 - val_recall_1: 0.9709 - learning_rate: 2.5000e-04\n",
      "Epoch 29/50\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9724 - auc_1: 0.9944 - loss: 0.1069 - precision_1: 0.9724 - recall_1: 0.9724\n",
      "Epoch 29: val_loss improved from 0.11419 to 0.10988, saving model to best_mlf_model.keras\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m289s\u001b[0m 2s/step - accuracy: 0.9724 - auc_1: 0.9944 - loss: 0.1070 - precision_1: 0.9724 - recall_1: 0.9724 - val_accuracy: 0.9725 - val_auc_1: 0.9945 - val_loss: 0.1099 - val_precision_1: 0.9725 - val_recall_1: 0.9725 - learning_rate: 2.5000e-04\n",
      "Epoch 30/50\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9632 - auc_1: 0.9924 - loss: 0.1295 - precision_1: 0.9632 - recall_1: 0.9632\n",
      "Epoch 30: val_loss did not improve from 0.10988\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m290s\u001b[0m 2s/step - accuracy: 0.9632 - auc_1: 0.9924 - loss: 0.1295 - precision_1: 0.9632 - recall_1: 0.9632 - val_accuracy: 0.9618 - val_auc_1: 0.9937 - val_loss: 0.1210 - val_precision_1: 0.9618 - val_recall_1: 0.9618 - learning_rate: 2.5000e-04\n",
      "Epoch 31/50\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9662 - auc_1: 0.9929 - loss: 0.1186 - precision_1: 0.9662 - recall_1: 0.9662\n",
      "Epoch 31: val_loss improved from 0.10988 to 0.10988, saving model to best_mlf_model.keras\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m301s\u001b[0m 2s/step - accuracy: 0.9662 - auc_1: 0.9929 - loss: 0.1186 - precision_1: 0.9662 - recall_1: 0.9662 - val_accuracy: 0.9709 - val_auc_1: 0.9936 - val_loss: 0.1099 - val_precision_1: 0.9709 - val_recall_1: 0.9709 - learning_rate: 2.5000e-04\n",
      "Epoch 32/50\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9683 - auc_1: 0.9926 - loss: 0.1196 - precision_1: 0.9683 - recall_1: 0.9683\n",
      "Epoch 32: val_loss did not improve from 0.10988\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m270s\u001b[0m 2s/step - accuracy: 0.9683 - auc_1: 0.9926 - loss: 0.1196 - precision_1: 0.9683 - recall_1: 0.9683 - val_accuracy: 0.9755 - val_auc_1: 0.9938 - val_loss: 0.1109 - val_precision_1: 0.9755 - val_recall_1: 0.9755 - learning_rate: 2.5000e-04\n",
      "Epoch 33/50\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9623 - auc_1: 0.9905 - loss: 0.1370 - precision_1: 0.9623 - recall_1: 0.9623\n",
      "Epoch 33: val_loss did not improve from 0.10988\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m265s\u001b[0m 2s/step - accuracy: 0.9623 - auc_1: 0.9905 - loss: 0.1369 - precision_1: 0.9623 - recall_1: 0.9623 - val_accuracy: 0.9526 - val_auc_1: 0.9895 - val_loss: 0.1522 - val_precision_1: 0.9526 - val_recall_1: 0.9526 - learning_rate: 2.5000e-04\n",
      "Epoch 34/50\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.9640 - auc_1: 0.9903 - loss: 0.1320 - precision_1: 0.9640 - recall_1: 0.9640\n",
      "Epoch 34: val_loss improved from 0.10988 to 0.10141, saving model to best_mlf_model.keras\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m870s\u001b[0m 5s/step - accuracy: 0.9640 - auc_1: 0.9903 - loss: 0.1319 - precision_1: 0.9640 - recall_1: 0.9640 - val_accuracy: 0.9709 - val_auc_1: 0.9959 - val_loss: 0.1014 - val_precision_1: 0.9709 - val_recall_1: 0.9709 - learning_rate: 2.5000e-04\n",
      "Epoch 35/50\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9667 - auc_1: 0.9930 - loss: 0.1198 - precision_1: 0.9667 - recall_1: 0.9667\n",
      "Epoch 35: val_loss did not improve from 0.10141\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m264s\u001b[0m 2s/step - accuracy: 0.9667 - auc_1: 0.9930 - loss: 0.1198 - precision_1: 0.9667 - recall_1: 0.9667 - val_accuracy: 0.9648 - val_auc_1: 0.9935 - val_loss: 0.1142 - val_precision_1: 0.9648 - val_recall_1: 0.9648 - learning_rate: 2.5000e-04\n",
      "Epoch 36/50\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9710 - auc_1: 0.9946 - loss: 0.1059 - precision_1: 0.9710 - recall_1: 0.9710\n",
      "Epoch 36: val_loss did not improve from 0.10141\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m267s\u001b[0m 2s/step - accuracy: 0.9710 - auc_1: 0.9946 - loss: 0.1059 - precision_1: 0.9710 - recall_1: 0.9710 - val_accuracy: 0.9633 - val_auc_1: 0.9944 - val_loss: 0.1180 - val_precision_1: 0.9633 - val_recall_1: 0.9633 - learning_rate: 2.5000e-04\n",
      "Epoch 37/50\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.9627 - auc_1: 0.9938 - loss: 0.1201 - precision_1: 0.9627 - recall_1: 0.9627\n",
      "Epoch 37: val_loss improved from 0.10141 to 0.09920, saving model to best_mlf_model.keras\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m663s\u001b[0m 4s/step - accuracy: 0.9627 - auc_1: 0.9938 - loss: 0.1201 - precision_1: 0.9627 - recall_1: 0.9627 - val_accuracy: 0.9740 - val_auc_1: 0.9962 - val_loss: 0.0992 - val_precision_1: 0.9740 - val_recall_1: 0.9740 - learning_rate: 2.5000e-04\n",
      "Epoch 38/50\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9737 - auc_1: 0.9944 - loss: 0.1015 - precision_1: 0.9737 - recall_1: 0.9737\n",
      "Epoch 38: val_loss improved from 0.09920 to 0.09557, saving model to best_mlf_model.keras\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m282s\u001b[0m 2s/step - accuracy: 0.9737 - auc_1: 0.9944 - loss: 0.1016 - precision_1: 0.9737 - recall_1: 0.9737 - val_accuracy: 0.9740 - val_auc_1: 0.9963 - val_loss: 0.0956 - val_precision_1: 0.9740 - val_recall_1: 0.9740 - learning_rate: 2.5000e-04\n",
      "Epoch 39/50\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9735 - auc_1: 0.9955 - loss: 0.0946 - precision_1: 0.9735 - recall_1: 0.9735\n",
      "Epoch 39: val_loss did not improve from 0.09557\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m290s\u001b[0m 2s/step - accuracy: 0.9735 - auc_1: 0.9955 - loss: 0.0947 - precision_1: 0.9735 - recall_1: 0.9735 - val_accuracy: 0.9709 - val_auc_1: 0.9956 - val_loss: 0.1037 - val_precision_1: 0.9709 - val_recall_1: 0.9709 - learning_rate: 2.5000e-04\n",
      "Epoch 40/50\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9683 - auc_1: 0.9926 - loss: 0.1193 - precision_1: 0.9683 - recall_1: 0.9683\n",
      "Epoch 40: val_loss did not improve from 0.09557\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m298s\u001b[0m 2s/step - accuracy: 0.9683 - auc_1: 0.9926 - loss: 0.1192 - precision_1: 0.9683 - recall_1: 0.9683 - val_accuracy: 0.9740 - val_auc_1: 0.9950 - val_loss: 0.0996 - val_precision_1: 0.9740 - val_recall_1: 0.9740 - learning_rate: 2.5000e-04\n",
      "Epoch 41/50\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9774 - auc_1: 0.9955 - loss: 0.0892 - precision_1: 0.9774 - recall_1: 0.9774\n",
      "Epoch 41: val_loss did not improve from 0.09557\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m287s\u001b[0m 2s/step - accuracy: 0.9774 - auc_1: 0.9955 - loss: 0.0893 - precision_1: 0.9774 - recall_1: 0.9774 - val_accuracy: 0.9740 - val_auc_1: 0.9950 - val_loss: 0.1012 - val_precision_1: 0.9740 - val_recall_1: 0.9740 - learning_rate: 2.5000e-04\n",
      "Epoch 42/50\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9793 - auc_1: 0.9940 - loss: 0.0943 - precision_1: 0.9793 - recall_1: 0.9793\n",
      "Epoch 42: val_loss did not improve from 0.09557\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m264s\u001b[0m 2s/step - accuracy: 0.9793 - auc_1: 0.9940 - loss: 0.0943 - precision_1: 0.9793 - recall_1: 0.9793 - val_accuracy: 0.9755 - val_auc_1: 0.9960 - val_loss: 0.0973 - val_precision_1: 0.9755 - val_recall_1: 0.9755 - learning_rate: 2.5000e-04\n",
      "Epoch 43/50\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9719 - auc_1: 0.9946 - loss: 0.0982 - precision_1: 0.9719 - recall_1: 0.9719\n",
      "Epoch 43: val_loss improved from 0.09557 to 0.09317, saving model to best_mlf_model.keras\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m266s\u001b[0m 2s/step - accuracy: 0.9720 - auc_1: 0.9946 - loss: 0.0981 - precision_1: 0.9720 - recall_1: 0.9720 - val_accuracy: 0.9771 - val_auc_1: 0.9970 - val_loss: 0.0932 - val_precision_1: 0.9771 - val_recall_1: 0.9771 - learning_rate: 2.5000e-04\n",
      "Epoch 44/50\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.9751 - auc_1: 0.9938 - loss: 0.1033 - precision_1: 0.9751 - recall_1: 0.9751\n",
      "Epoch 44: val_loss did not improve from 0.09317\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m508s\u001b[0m 3s/step - accuracy: 0.9750 - auc_1: 0.9938 - loss: 0.1033 - precision_1: 0.9750 - recall_1: 0.9750 - val_accuracy: 0.9725 - val_auc_1: 0.9964 - val_loss: 0.0961 - val_precision_1: 0.9725 - val_recall_1: 0.9725 - learning_rate: 2.5000e-04\n",
      "Epoch 45/50\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9764 - auc_1: 0.9952 - loss: 0.0945 - precision_1: 0.9764 - recall_1: 0.9764\n",
      "Epoch 45: val_loss did not improve from 0.09317\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m265s\u001b[0m 2s/step - accuracy: 0.9764 - auc_1: 0.9952 - loss: 0.0945 - precision_1: 0.9764 - recall_1: 0.9764 - val_accuracy: 0.9771 - val_auc_1: 0.9967 - val_loss: 0.0966 - val_precision_1: 0.9771 - val_recall_1: 0.9771 - learning_rate: 2.5000e-04\n",
      "Epoch 46/50\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9746 - auc_1: 0.9946 - loss: 0.0935 - precision_1: 0.9746 - recall_1: 0.9746\n",
      "Epoch 46: val_loss did not improve from 0.09317\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m266s\u001b[0m 2s/step - accuracy: 0.9746 - auc_1: 0.9947 - loss: 0.0935 - precision_1: 0.9746 - recall_1: 0.9746 - val_accuracy: 0.9755 - val_auc_1: 0.9972 - val_loss: 0.0975 - val_precision_1: 0.9755 - val_recall_1: 0.9755 - learning_rate: 2.5000e-04\n",
      "Epoch 47/50\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9748 - auc_1: 0.9946 - loss: 0.0933 - precision_1: 0.9748 - recall_1: 0.9748\n",
      "Epoch 47: val_loss did not improve from 0.09317\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 2s/step - accuracy: 0.9748 - auc_1: 0.9946 - loss: 0.0934 - precision_1: 0.9748 - recall_1: 0.9748 - val_accuracy: 0.9725 - val_auc_1: 0.9981 - val_loss: 0.0950 - val_precision_1: 0.9725 - val_recall_1: 0.9725 - learning_rate: 2.5000e-04\n",
      "Epoch 48/50\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9725 - auc_1: 0.9947 - loss: 0.0956 - precision_1: 0.9725 - recall_1: 0.9725\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 48: val_loss did not improve from 0.09317\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 2s/step - accuracy: 0.9725 - auc_1: 0.9947 - loss: 0.0956 - precision_1: 0.9725 - recall_1: 0.9725 - val_accuracy: 0.9679 - val_auc_1: 0.9971 - val_loss: 0.1118 - val_precision_1: 0.9679 - val_recall_1: 0.9679 - learning_rate: 2.5000e-04\n",
      "Epoch 49/50\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.9740 - auc_1: 0.9959 - loss: 0.0929 - precision_1: 0.9740 - recall_1: 0.9740\n",
      "Epoch 49: val_loss improved from 0.09317 to 0.09313, saving model to best_mlf_model.keras\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m436s\u001b[0m 3s/step - accuracy: 0.9740 - auc_1: 0.9959 - loss: 0.0929 - precision_1: 0.9740 - recall_1: 0.9740 - val_accuracy: 0.9725 - val_auc_1: 0.9975 - val_loss: 0.0931 - val_precision_1: 0.9725 - val_recall_1: 0.9725 - learning_rate: 1.2500e-04\n",
      "Epoch 50/50\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9770 - auc_1: 0.9955 - loss: 0.0899 - precision_1: 0.9770 - recall_1: 0.9770\n",
      "Epoch 50: val_loss improved from 0.09313 to 0.09160, saving model to best_mlf_model.keras\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 2s/step - accuracy: 0.9770 - auc_1: 0.9955 - loss: 0.0898 - precision_1: 0.9770 - recall_1: 0.9770 - val_accuracy: 0.9771 - val_auc_1: 0.9978 - val_loss: 0.0916 - val_precision_1: 0.9771 - val_recall_1: 0.9771 - learning_rate: 1.2500e-04\n",
      "The training time is 18840.69952583313 seconds.\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 715ms/step\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.98      1.00      0.99       612\n",
      "     Class 1       0.94      0.69      0.79        42\n",
      "\n",
      "    accuracy                           0.98       654\n",
      "   macro avg       0.96      0.84      0.89       654\n",
      "weighted avg       0.98      0.98      0.98       654\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 709ms/step - accuracy: 0.9863 - auc_1: 0.9987 - loss: 0.0577 - precision_1: 0.9863 - recall_1: 0.9863\n",
      "\n",
      "Test Loss: 0.0916\n",
      "Test Accuracy: 0.9771\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.09160470217466354, 0.9770641922950745)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the additive fusion model\n",
    "history = train_fusion_model(\n",
    "    additive_fusion_model,\n",
    "    X_train_unet,\n",
    "    X_train_lstm,\n",
    "    Y_train,\n",
    "    X_test_unet,\n",
    "    X_test_lstm,\n",
    "    Y_test,\n",
    "    epochs=50\n",
    ")\n",
    "\n",
    "# Plot training\n",
    "plot_training_history(history)\n",
    "\n",
    "# Evaluate the model\n",
    "evaluate_fusion_model(\n",
    "    additive_fusion_model,\n",
    "    X_test_unet,\n",
    "    X_test_lstm,\n",
    "    Y_test\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Technique: Gated Fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "Train the fusion model with the UNet and LSTM features and considering the output of the LSTM and UNet models\n",
    "\"\"\"\n",
    "\n",
    "# print(\"Given input shape: \", [X_train_unet.shape, X_train_lstm.shape])\n",
    "# print(\"Given output shape: \", Y_train.shape)\n",
    "\n",
    "# Train the gated fusion model\n",
    "history = train_fusion_model(\n",
    "    gated_fusion_model,\n",
    "    X_train_unet,\n",
    "    X_train_lstm,\n",
    "    Y_train,\n",
    "    X_test_unet,\n",
    "    X_test_lstm,\n",
    "    Y_test,\n",
    "    epochs=50\n",
    ")\n",
    "\n",
    "# Plot training\n",
    "# plot_training_history(history)\n",
    "\n",
    "# # Evaluate the model\n",
    "evaluate_fusion_model(\n",
    "    gated_fusion_model,\n",
    "    X_test_unet,\n",
    "    X_test_lstm,\n",
    "    Y_test\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
