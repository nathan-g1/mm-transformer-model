{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tif', 'IS2_LSTM', 'ATL03_ow_labeled_10m_5km_corrected_new_sea_surface_LSTM_ann_prepared.csv', 'ATL03_S2_2019-11-01_2019-11-30_ross_renamed.csv', 'csv.zip', 'S2_Parallel_Workflow', '.DS_Store', 'reqiuirements.txt', 'png', 'env', 'Before_training.zip', '.gitignore', 'S2_data_explanableAI', '.gitattributes', '.git', 'data', 'S2_tif', 'ATL03_S2_2019-11-01_2019-11-30_ross.csv', 'src']\n",
      "/Users/nathan/Documents/Files/Grad/UTSA/Courses/Thesis/mm-transformer-model/MML\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# list current directory and path\n",
    "import os\n",
    "print(os.listdir('.'))\n",
    "path1 = os.path.join(os.path.abspath('.'), \"MML\")\n",
    "print(path1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset1 /Users/nathan/Documents/Files/Grad/UTSA/Courses/Thesis/mm-transformer-model/IS2_LSTM\n",
      "dataset2 /Users/nathan/Documents/Files/Grad/UTSA/Courses/Thesis/mm-transformer-model/S2_tif\n",
      "Number of ATL03 files:  15\n",
      "Number of S2_TIF files:  52\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "\n",
    "path1 = os.path.abspath('.')\n",
    "path_ATL03 = os.path.join(path1, \"IS2_LSTM\")\n",
    "path_s2 = os.path.join(path1, \"S2_tif\")\n",
    "path_csv = os.path.join(path1, \"csv\")\n",
    "path_before_training = os.path.join(path1, \"Before_training\")\n",
    "\n",
    "\n",
    "print(\"dataset1\", path_ATL03)\n",
    "print(\"dataset2\", path_s2)\n",
    "\n",
    "# Count number of files in ATL03 using a for loop\n",
    "num_files = 0\n",
    "for root, dirs, files in os.walk(path_ATL03):\n",
    "    num_files += len(files)\n",
    "print(\"Number of ATL03 files: \", num_files)\n",
    "\n",
    "\n",
    "# Count number of files in S2_TIF using a for loop\n",
    "num_s2_files = 0\n",
    "s2_files = []\n",
    "for root, dirs, files in os.walk(path_s2):\n",
    "    num_s2_files += len(files)\n",
    "    s2_files.append(files)\n",
    "\n",
    "print(\"Number of S2_TIF files: \", num_s2_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"_summary_\n",
    "    Run this script on local machine using \"gdaltest\" python env\n",
    "    import os\n",
    "    from osgeo import gdal\n",
    "    from datetime import datetime\n",
    "    from pathlib import Path\n",
    "\n",
    "    options_list = [\n",
    "        #'-ot Byte',\n",
    "        '-of PNG'\n",
    "        #'-b 1',\n",
    "        #'-scale'\n",
    "    ]\n",
    "\n",
    "    options_string = \" \".join(options_list)\n",
    "    tif_dir = \"S2_tif\"\n",
    "    for i, filename in enumerate(os.listdir(tif_dir)):\n",
    "        filename_split = filename.split('_')\n",
    "        img_type = filename_split[len(filename_split) - 1]\n",
    "        date_string = filename_split[3]\n",
    "        date = datetime.strptime(date_string, '%Y%m%dT%H%M%S').date()\n",
    "        new_filename = str(i) + \"_\" + str(date) + \"_\" + img_type.replace(\"tif\", \"png\")\n",
    "\n",
    "        gdal.Translate(\n",
    "            os.path.join(\"png\", new_filename),\n",
    "            os.path.join(tif_dir, filename),\n",
    "            options=options_string\n",
    "        )\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Header of CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Header\n",
      "0    Unnamed: 0\n",
      "1          year\n",
      "2         month\n",
      "3           day\n",
      "4          hour\n",
      "5        minute\n",
      "6        second\n",
      "7           lat\n",
      "8           lon\n",
      "9             x\n",
      "10            y\n",
      "11          dac\n",
      "12        geoid\n",
      "13         tide\n",
      "14        s_azi\n",
      "15        s_ele\n",
      "16            N\n",
      "17  height_mean\n",
      "18    pcnt_mean\n",
      "19   pcnth_mean\n",
      "20    bcnt_mean\n",
      "21   brate_mean\n",
      "22    height_sd\n",
      "23      pcnt_sd\n",
      "24     pcnth_sd\n",
      "25      bcnt_sd\n",
      "26     brate_sd\n",
      "27   height_med\n",
      "28     pcnt_med\n",
      "29    pcnth_med\n",
      "30     bcnt_med\n",
      "31    brate_med\n",
      "32     fpb_corr\n",
      "33          mss\n",
      "34   h_cor_mean\n",
      "35    h_cor_med\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# List to store the headers\n",
    "headers_list = []\n",
    "\n",
    "# Iterate through each file in path_csv and read the header\n",
    "for root, dirs, files in os.walk(path_csv):\n",
    "    for file in files:\n",
    "        file_path = os.path.join(root, file)\n",
    "        df_temp = pd.read_csv(file_path, nrows=0)  # Read only the header\n",
    "        # If there is a mismatch in the number of columns, handle it the ones with less by adding None. \n",
    "        # Check the the max number of columns in the list of headers and add None to the ones with less columns\n",
    "        if len(df_temp.columns) < len(headers_list):\n",
    "            diff = len(headers_list) - len(df_temp.columns)\n",
    "            for i in range(diff):\n",
    "                df_temp[headers_list[-1] + str(i)] = None\n",
    "        headers_list = list(df_temp.columns)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Create a DataFrame from the headers list\n",
    "headers_df = pd.DataFrame(headers_list, columns=['Header'])\n",
    "print(headers_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# List to store the number of rows in each file\n",
    "rows_in_files = []\n",
    "\n",
    "# Iterate through each file in path_ATL03 and count the number of rows\n",
    "for root, dirs, files in os.walk(path_ATL03):\n",
    "    for file in files:\n",
    "        file_path = os.path.join(root, file)\n",
    "        df_temp = pd.read_csv(file_path)\n",
    "        rows_in_files.append(len(df_temp))\n",
    "\n",
    "# Plot the histogram\n",
    "plt.hist(rows_in_files, bins=20, edgecolor='black')\n",
    "plt.title('Histogram of Rows in Each File in path_ATL03')\n",
    "plt.xlabel('Number of Rows')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List to store the class distribution for each file\n",
    "class_distributions = []\n",
    "\n",
    "# Iterate through each file in path_ATL03 and get the class distribution\n",
    "for root, dirs, files in os.walk(path_ATL03):\n",
    "    for file in files:\n",
    "        file_path = os.path.join(root, file)\n",
    "        df_temp = pd.read_csv(file_path)\n",
    "        class_distributions.extend(df_temp['label'].values)\n",
    "\n",
    "# Plot the histogram\n",
    "plt.hist(class_distributions, bins=[-0.5, 0.5, 1.5, 2.5], edgecolor='black')\n",
    "plt.title('Histogram of Class Distribution in Each File in path_ATL03')\n",
    "plt.xlabel('Class Label')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xticks([0, 1, 2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Count the occurrences of each class\n",
    "class_counts = np.bincount(class_distributions)\n",
    "\n",
    "# Plot the line graph\n",
    "plt.plot(class_counts, marker='o')\n",
    "plt.title('Line Graph of Class Distribution in Each File in path_ATL03')\n",
    "plt.xlabel('Class Label')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xticks([0, 1, 2])\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Plot the class distribution of each file in a different color\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Iterate through each file in path_ATL03 and plot the class distribution\n",
    "for root, dirs, files in os.walk(path_ATL03):\n",
    "    for file in files:\n",
    "        file_path = os.path.join(root, file)\n",
    "        df_temp = pd.read_csv(file_path)\n",
    "        class_counts_temp = np.bincount(df_temp['label'].astype(int))\n",
    "        plt.plot(class_counts_temp, marker='o', label=file)\n",
    "\n",
    "plt.title('Class Distribution in Each File in path_ATL03')\n",
    "plt.xlabel('Class Label')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xticks([0, 1, 2])\n",
    "plt.legend(loc='upper right', bbox_to_anchor=(1.15, 1))\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
